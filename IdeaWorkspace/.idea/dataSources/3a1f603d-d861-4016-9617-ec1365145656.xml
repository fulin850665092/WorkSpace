<?xml version="1.0" encoding="UTF-8"?>
<dataSource name="hive">
  <database-model serializer="dbm" dbms="HIVE" family-id="HIVE" format-version="4.15">
    <root id="1">
      <ServerVersion>3.1.2</ServerVersion>
    </root>
    <schema id="2" parent="1" name="atguigu">
      <Visible>1</Visible>
      <Location>hdfs://hadoop102:8020/user/hive/warehouse/atguigu.db</Location>
    </schema>
    <schema id="3" parent="1" name="default">
      <Comment>Default Hive database</Comment>
      <Current>1</Current>
      <Visible>1</Visible>
      <Location>hdfs://hadoop102:8020/user/hive/warehouse</Location>
    </schema>
    <schema id="4" parent="1" name="dt">
      <Properties>creattime
20200101</Properties>
      <Visible>1</Visible>
      <Location>hdfs://hadoop102:8020/user/hive/warehouse/dt.db</Location>
    </schema>
    <schema id="5" parent="1" name="mydb">
      <Properties>creatim
2020-03-25</Properties>
      <Visible>1</Visible>
      <Location>hdfs://hadoop102:8020/user/hive/warehouse/mydb.db</Location>
    </schema>
    <routine id="6" parent="1" name="abs">
      <Comment>abs(x) - returns the absolute value of x</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFAbs</ClassName>
    </routine>
    <routine id="7" parent="1" name="acos">
      <Comment>acos(x) - returns the arc cosine of x if -1&lt;=x&lt;=1 or NULL otherwise</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.UDFAcos</ClassName>
    </routine>
    <routine id="8" parent="1" name="add_months">
      <Comment>add_months(start_date, num_months, output_date_format) - Returns the date that is num_months after start_date.</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFAddMonths</ClassName>
    </routine>
    <routine id="9" parent="1" name="aes_decrypt">
      <Comment>aes_decrypt(input binary, key string/binary) - Decrypt input using AES.</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFAesDecrypt</ClassName>
    </routine>
    <routine id="10" parent="1" name="aes_encrypt">
      <Comment>aes_encrypt(input string/binary, key string/binary) - Encrypt input using AES.</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFAesEncrypt</ClassName>
    </routine>
    <routine id="11" parent="1" name="array">
      <Comment>array(n0, n1...) - Creates an array with the given elements</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFArray</ClassName>
    </routine>
    <routine id="12" parent="1" name="array_contains">
      <Comment>array_contains(array, value) - Returns TRUE if the array contains value.</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFArrayContains</ClassName>
    </routine>
    <routine id="13" parent="1" name="ascii">
      <Comment>ascii(str) - returns the numeric value of the first character of str</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.UDFAscii</ClassName>
    </routine>
    <routine id="14" parent="1" name="asin">
      <Comment>asin(x) - returns the arc sine of x if -1&lt;=x&lt;=1 or NULL otherwise</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.UDFAsin</ClassName>
    </routine>
    <routine id="15" parent="1" name="assert_true">
      <Comment>assert_true(condition) - Throw an exception if &apos;condition&apos; is not true.</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFAssertTrue</ClassName>
    </routine>
    <routine id="16" parent="1" name="assert_true_oom">
      <Comment>There is no documentation for function &apos;assert_true_oom&apos;</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFAssertTrueOOM</ClassName>
    </routine>
    <routine id="17" parent="1" name="atan">
      <Comment>atan(x) - returns the atan (arctan) of x (x is in radians)</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.UDFAtan</ClassName>
    </routine>
    <routine id="18" parent="1" name="avg">
      <Comment>avg(x) - Returns the mean of a set of numbers</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDAFAverage</ClassName>
    </routine>
    <routine id="19" parent="1" name="base64">
      <Comment>base64(bin) - Convert the argument from binary to a base 64 string</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.UDFBase64</ClassName>
    </routine>
    <routine id="20" parent="1" name="bin">
      <Comment>bin(n) - returns n in binary</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.UDFBin</ClassName>
    </routine>
    <routine id="21" parent="1" name="bloom_filter">
      <Comment>There is no documentation for function &apos;bloom_filter&apos;</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDAFBloomFilter</ClassName>
    </routine>
    <routine id="22" parent="1" name="bround">
      <Comment>bround(x[, d]) - round x to d decimal places using HALF_EVEN rounding mode.</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFBRound</ClassName>
    </routine>
    <routine id="23" parent="1" name="cardinality_violation">
      <Comment>cardinality_violation(n0, n1...) - raises Cardinality Violation</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFCardinalityViolation</ClassName>
    </routine>
    <routine id="24" parent="1" name="cbrt">
      <Comment>cbrt(double) - Returns the cube root of a double value.</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFCbrt</ClassName>
    </routine>
    <routine id="25" parent="1" name="ceil">
      <Comment>ceil(x) - Find the smallest integer not smaller than x</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFCeil</ClassName>
    </routine>
    <routine id="26" parent="1" name="ceiling">
      <Comment>ceiling(x) - Find the smallest integer not smaller than x</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFCeil</ClassName>
    </routine>
    <routine id="27" parent="1" name="char_length">
      <Comment>char_length(str | binary) - Returns the number of characters in str or binary data</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFCharacterLength</ClassName>
    </routine>
    <routine id="28" parent="1" name="character_length">
      <Comment>character_length(str | binary) - Returns the number of characters in str or binary data</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFCharacterLength</ClassName>
    </routine>
    <routine id="29" parent="1" name="chr">
      <Comment>chr(str) - convert n where n : [0, 256) into the ascii equivalent as a varchar.If n is less than 0 return the empty string. If n &gt; 256, return chr(n % 256).</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.UDFChr</ClassName>
    </routine>
    <routine id="30" parent="1" name="coalesce">
      <Comment>coalesce(a1, a2, ...) - Returns the first non-null argument</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFCoalesce</ClassName>
    </routine>
    <routine id="31" parent="1" name="collect_list">
      <Comment>collect_list(x) - Returns a list of objects with duplicates</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDAFCollectList</ClassName>
    </routine>
    <routine id="32" parent="1" name="collect_set">
      <Comment>collect_set(x) - Returns a set of objects with duplicate elements eliminated</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDAFCollectSet</ClassName>
    </routine>
    <routine id="33" parent="1" name="compute_stats">
      <Comment>compute_stats(x) - Returns the statistical summary of a set of primitive type values.</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDAFComputeStats</ClassName>
    </routine>
    <routine id="34" parent="1" name="concat">
      <Comment>concat(str1, str2, ... strN) - returns the concatenation of str1, str2, ... strN or concat(bin1, bin2, ... binN) - returns the concatenation of bytes in binary data  bin1, bin2, ... binN</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFConcat</ClassName>
    </routine>
    <routine id="35" parent="1" name="concat_ws">
      <Comment>concat_ws(separator, [string | array(string)]+) - returns the concatenation of the strings separated by the separator.</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFConcatWS</ClassName>
    </routine>
    <routine id="36" parent="1" name="context_ngrams">
      <Comment>context_ngrams(expr, array&lt;string1, string2, ...&gt;, k, pf) estimates the top-k most frequent n-grams that fit into the specified context. The second parameter specifies a string of words that specify the positions of the n-gram elements, with a null value standing in for a &apos;blank&apos; that must be filled by an n-gram element.</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDAFContextNGrams</ClassName>
    </routine>
    <routine id="37" parent="1" name="conv">
      <Comment>conv(num, from_base, to_base) - convert num from from_base to to_base</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.UDFConv</ClassName>
    </routine>
    <routine id="38" parent="1" name="corr">
      <Comment>corr(y,x) - Returns the Pearson coefficient of correlation</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDAFCorrelation</ClassName>
    </routine>
    <routine id="39" parent="1" name="cos">
      <Comment>cos(x) - returns the cosine of x (x is in radians)</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.UDFCos</ClassName>
    </routine>
    <routine id="40" parent="1" name="count">
      <Comment>count(*) - Returns the total number of retrieved rows, including rows containing NULL values.</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDAFCount</ClassName>
    </routine>
    <routine id="41" parent="1" name="covar_pop">
      <Comment>covar_pop(x,y) - Returns the population covariance of a set of number pairs</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDAFCovariance</ClassName>
    </routine>
    <routine id="42" parent="1" name="covar_samp">
      <Comment>covar_samp(x,y) - Returns the sample covariance of a set of number pairs</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDAFCovarianceSample</ClassName>
    </routine>
    <routine id="43" parent="1" name="crc32">
      <Comment>crc32(str or bin) - Computes a cyclic redundancy check value for string or binary argument and returns bigint value.</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.UDFCrc32</ClassName>
    </routine>
    <routine id="44" parent="1" name="create_union">
      <Comment>create_union(tag, obj1, obj2, obj3, ...) - Creates a union with the object for given tag</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFUnion</ClassName>
    </routine>
    <routine id="45" parent="1" name="cume_dist">
      <Comment>There is no documentation for function &apos;cume_dist&apos;</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDAFCumeDist</ClassName>
    </routine>
    <routine id="46" parent="1" name="current_authorizer">
      <Comment>current_authorizer() - Returns the current authorizer (class name of the authorizer).</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFCurrentAuthorizer</ClassName>
    </routine>
    <routine id="47" parent="1" name="current_database">
      <Comment>current_database() - returns currently using database name</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.UDFCurrentDB</ClassName>
    </routine>
    <routine id="48" parent="1" name="current_date">
      <Comment>current_date() - Returns the current date at the start of query evaluation. All calls of current_date within the same query return the same value.</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFCurrentDate</ClassName>
    </routine>
    <routine id="49" parent="1" name="current_groups">
      <Comment>current_groups() - Returns all groups the current user belongs to</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFCurrentGroups</ClassName>
    </routine>
    <routine id="50" parent="1" name="current_timestamp">
      <Comment>current_timestamp() - Returns the current timestamp at the start of query evaluation. All calls of current_timestamp within the same query return the same value.</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFCurrentTimestamp</ClassName>
    </routine>
    <routine id="51" parent="1" name="current_user">
      <Comment>current_user() - Returns current user name</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFCurrentUser</ClassName>
    </routine>
    <routine id="52" parent="1" name="date_add">
      <Comment>date_add(start_date, num_days) - Returns the date that is num_days after start_date.</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFDateAdd</ClassName>
    </routine>
    <routine id="53" parent="1" name="date_format">
      <Comment>date_format(date/timestamp/string, fmt) - converts a date/timestamp/string to a value of string in the format specified by the date format fmt.</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFDateFormat</ClassName>
    </routine>
    <routine id="54" parent="1" name="date_sub">
      <Comment>date_sub(start_date, num_days) - Returns the date that is num_days before start_date.</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFDateSub</ClassName>
    </routine>
    <routine id="55" parent="1" name="datediff">
      <Comment>datediff(date1, date2) - Returns the number of days between date1 and date2</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFDateDiff</ClassName>
    </routine>
    <routine id="56" parent="1" name="day">
      <Comment>day(param) - Returns the day of the month of date/timestamp, or day component of interval</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.UDFDayOfMonth</ClassName>
    </routine>
    <routine id="57" parent="1" name="dayofmonth">
      <Comment>dayofmonth(param) - Returns the day of the month of date/timestamp, or day component of interval</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.UDFDayOfMonth</ClassName>
    </routine>
    <routine id="58" parent="1" name="dayofweek">
      <Comment>dayofweek(param) - Returns the day of the week of date/timestamp (1 = Sunday, 2 = Monday, ..., 7 = Saturday)</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.UDFDayOfWeek</ClassName>
    </routine>
    <routine id="59" parent="1" name="decode">
      <Comment>decode(bin, str) - Decode the first argument using the second argument character set</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFDecode</ClassName>
    </routine>
    <routine id="60" parent="1" name="degrees">
      <Comment>degrees(x) - Converts radians to degrees</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.UDFDegrees</ClassName>
    </routine>
    <routine id="61" parent="1" name="dense_rank">
      <Comment>There is no documentation for function &apos;dense_rank&apos;</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDAFDenseRank</ClassName>
    </routine>
    <routine id="62" parent="1" name="e">
      <Comment>e() - returns E</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.UDFE</ClassName>
    </routine>
    <routine id="63" parent="1" name="elt">
      <Comment>elt(n, str1, str2, ...) - returns the n-th string</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFElt</ClassName>
    </routine>
    <routine id="64" parent="1" name="encode">
      <Comment>encode(str, str) - Encode the first argument using the second argument character set</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFEncode</ClassName>
    </routine>
    <routine id="65" parent="1" name="enforce_constraint">
      <Comment>enforce_constraint(x) - Internal UDF to enforce CHECK and NOT NULL constraint</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFEnforceConstraint</ClassName>
    </routine>
    <routine id="66" parent="1" name="exp">
      <Comment>exp(x) - Returns e to the power of x</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.UDFExp</ClassName>
    </routine>
    <routine id="67" parent="1" name="explode">
      <Comment>explode(a) - separates the elements of array a into multiple rows, or the elements of a map into multiple rows and columns</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDTFExplode</ClassName>
    </routine>
    <routine id="68" parent="1" name="extract_union">
      <Comment>extract_union(union[, tag]) - Recursively explodes unions into structs or simply extracts the given tag.</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFExtractUnion</ClassName>
    </routine>
    <routine id="69" parent="1" name="factorial">
      <Comment>factorial(int) - Returns n factorial. Valid n is [0..20].</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFFactorial</ClassName>
    </routine>
    <routine id="70" parent="1" name="field">
      <Comment>field(str, str1, str2, ...) - returns the index of str in the str1,str2,... list or 0 if not found</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFField</ClassName>
    </routine>
    <routine id="71" parent="1" name="find_in_set">
      <Comment>find_in_set(str,str_array) - Returns the first occurrence  of str in str_array where str_array is a comma-delimited string. Returns null if either argument is null. Returns 0 if the first argument has any commas.</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.UDFFindInSet</ClassName>
    </routine>
    <routine id="72" parent="1" name="first_value">
      <Comment>There is no documentation for function &apos;first_value&apos;</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDAFFirstValue</ClassName>
    </routine>
    <routine id="73" parent="1" name="floor">
      <Comment>floor(x) - Find the largest integer not greater than x</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFFloor</ClassName>
    </routine>
    <routine id="74" parent="1" name="floor_day">
      <Comment>floor_day(param) - Returns the timestamp at a day granularity</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.UDFDateFloorDay</ClassName>
    </routine>
    <routine id="75" parent="1" name="floor_hour">
      <Comment>floor_hour(param) - Returns the timestamp at a hour granularity</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.UDFDateFloorHour</ClassName>
    </routine>
    <routine id="76" parent="1" name="floor_minute">
      <Comment>floor_minute(param) - Returns the timestamp at a minute granularity</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.UDFDateFloorMinute</ClassName>
    </routine>
    <routine id="77" parent="1" name="floor_month">
      <Comment>floor_month(param) - Returns the timestamp at a month granularity</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.UDFDateFloorMonth</ClassName>
    </routine>
    <routine id="78" parent="1" name="floor_quarter">
      <Comment>floor_quarter(param) - Returns the timestamp at a quarter granularity</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.UDFDateFloorQuarter</ClassName>
    </routine>
    <routine id="79" parent="1" name="floor_second">
      <Comment>floor_second(param) - Returns the timestamp at a second granularity</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.UDFDateFloorSecond</ClassName>
    </routine>
    <routine id="80" parent="1" name="floor_week">
      <Comment>floor_week(param) - Returns the timestamp at a week granularity</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.UDFDateFloorWeek</ClassName>
    </routine>
    <routine id="81" parent="1" name="floor_year">
      <Comment>floor_year(param) - Returns the timestamp at a year granularity</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.UDFDateFloorYear</ClassName>
    </routine>
    <routine id="82" parent="1" name="format_number">
      <Comment>format_number(X, D or F) - Formats the number X to a format like &apos;#,###,###.##&apos;, rounded to D decimal places, Or Uses the format specified F to format, and returns the result as a string. If D is 0, the result has no decimal point or fractional part. This is supposed to function like MySQL&apos;s FORMAT</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFFormatNumber</ClassName>
    </routine>
    <routine id="83" parent="1" name="from_unixtime">
      <Comment>from_unixtime(unix_time, format) - returns unix_time in the specified format</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.UDFFromUnixTime</ClassName>
    </routine>
    <routine id="84" parent="1" name="from_utc_timestamp">
      <Comment>from_utc_timestamp(timestamp, string timezone) - Assumes given timestamp is UTC and converts to given timezone (as of Hive 0.8.0)</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFFromUtcTimestamp</ClassName>
    </routine>
    <routine id="85" parent="1" name="get_json_object">
      <Comment>get_json_object(json_txt, path) - Extract a json object from path</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.UDFJson</ClassName>
    </routine>
    <routine id="86" parent="1" name="get_splits">
      <Comment>get_splits(string,int) - Returns an array of length int serialized splits for the referenced tables string. Passing length 0 returns only schema data for the compiled query.</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDTFGetSplits</ClassName>
    </routine>
    <routine id="87" parent="1" name="greatest">
      <Comment>greatest(v1, v2, ...) - Returns the greatest value in a list of values</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFGreatest</ClassName>
    </routine>
    <routine id="88" parent="1" name="grouping">
      <Comment>grouping(a, p1, ..., pn) - Indicates whether a specified column expression in is aggregated or not. Returns 1 for aggregated or 0 for not aggregated.</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFGrouping</ClassName>
    </routine>
    <routine id="89" parent="1" name="hash">
      <Comment>hash(a1, a2, ...) - Returns a hash value of the arguments</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFHash</ClassName>
    </routine>
    <routine id="90" parent="1" name="hex">
      <Comment>hex(n, bin, or str) - Convert the argument to hexadecimal</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.UDFHex</ClassName>
    </routine>
    <routine id="91" parent="1" name="histogram_numeric">
      <Comment>histogram_numeric(expr, nb) - Computes a histogram on numeric &apos;expr&apos; using nb bins.</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDAFHistogramNumeric</ClassName>
    </routine>
    <routine id="92" parent="1" name="hour">
      <Comment>hour(param) - Returns the hour componemnt of the string/timestamp/interval</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.UDFHour</ClassName>
    </routine>
    <routine id="93" parent="1" name="if">
      <Comment>IF(expr1,expr2,expr3) - If expr1 is TRUE (expr1 &lt;&gt; 0 and expr1 &lt;&gt; NULL) then IF() returns expr2; otherwise it returns expr3. IF() returns a numeric or string value, depending on the context in which it is used.</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFIf</ClassName>
    </routine>
    <routine id="94" parent="1" name="in_bloom_filter">
      <Comment>There is no documentation for function &apos;in_bloom_filter&apos;</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFInBloomFilter</ClassName>
    </routine>
    <routine id="95" parent="1" name="in_file">
      <Comment>in_file(str, filename) - Returns true if str appears in the file</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFInFile</ClassName>
    </routine>
    <routine id="96" parent="1" name="index">
      <Comment>index(a, n) - Returns the n-th element of a</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFIndex</ClassName>
    </routine>
    <routine id="97" parent="1" name="initcap">
      <Comment>initcap(str) - Returns str, with the first letter of each word in uppercase, all other letters in lowercase. Words are delimited by white space.</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFInitCap</ClassName>
    </routine>
    <routine id="98" parent="1" name="inline">
      <Comment>inline( ARRAY( STRUCT()[,STRUCT()] - explodes and array and struct into a table</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDTFInline</ClassName>
    </routine>
    <routine id="99" parent="1" name="instr">
      <Comment>instr(str, substr) - Returns the index of the first occurance of substr in str</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFInstr</ClassName>
    </routine>
    <routine id="100" parent="1" name="internal_interval">
      <Comment>internal_interval(intervalType,intervalArg)</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFInternalInterval</ClassName>
    </routine>
    <routine id="101" parent="1" name="isfalse">
      <Comment>isfalse a - Returns true if a is FALSE and false otherwise</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFOPFalse</ClassName>
    </routine>
    <routine id="102" parent="1" name="isnotfalse">
      <Comment>isnotfalse a - Returns true if a is NOT FALSE and false otherwise</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFOPNotFalse</ClassName>
    </routine>
    <routine id="103" parent="1" name="isnotnull">
      <Comment>isnotnull a - Returns true if a is not NULL and false otherwise</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFOPNotNull</ClassName>
    </routine>
    <routine id="104" parent="1" name="isnottrue">
      <Comment>isnottrue a - Returns true if a is NOT TRUE and false otherwise</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFOPNotTrue</ClassName>
    </routine>
    <routine id="105" parent="1" name="isnull">
      <Comment>isnull a - Returns true if a is NULL and false otherwise</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFOPNull</ClassName>
    </routine>
    <routine id="106" parent="1" name="istrue">
      <Comment>istrue a - Returns true if a is TRUE and false otherwise</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFOPTrue</ClassName>
    </routine>
    <routine id="107" parent="1" name="java_method">
      <Comment>java_method(class,method[,arg1[,arg2..]]) calls method with reflection</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFReflect</ClassName>
    </routine>
    <routine id="108" parent="1" name="json_tuple">
      <Comment>json_tuple(jsonStr, p1, p2, ..., pn) - like get_json_object, but it takes multiple names and return a tuple. All the input parameters and output column types are string.</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDTFJSONTuple</ClassName>
    </routine>
    <routine id="109" parent="1" name="lag">
      <Comment>LAG  (scalar_expression [,offset] [,default]) OVER ([query_partition_clause] order_by_clause); The LAG function is used to access data from a previous row.</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFLag</ClassName>
    </routine>
    <routine id="110" parent="1" name="last_day">
      <Comment>last_day(date) - Returns the last day of the month which the date belongs to.</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFLastDay</ClassName>
    </routine>
    <routine id="111" parent="1" name="last_value">
      <Comment>There is no documentation for function &apos;last_value&apos;</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDAFLastValue</ClassName>
    </routine>
    <routine id="112" parent="1" name="lcase">
      <Comment>lcase(str) - Returns str with all characters changed to lowercase</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFLower</ClassName>
    </routine>
    <routine id="113" parent="1" name="lead">
      <Comment>LEAD (scalar_expression [,offset] [,default]) OVER ([query_partition_clause] order_by_clause); The LEAD function is used to return data from the next row.</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFLead</ClassName>
    </routine>
    <routine id="114" parent="1" name="least">
      <Comment>least(v1, v2, ...) - Returns the least value in a list of values</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFLeast</ClassName>
    </routine>
    <routine id="115" parent="1" name="length">
      <Comment>length(str | binary) - Returns the length of str or number of bytes in binary data</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFLength</ClassName>
    </routine>
    <routine id="116" parent="1" name="levenshtein">
      <Comment>levenshtein(str1, str2) - This function calculates the Levenshtein distance between two strings.</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFLevenshtein</ClassName>
    </routine>
    <routine id="117" parent="1" name="likeall">
      <Comment>test likeall(pattern1, pattern2...) - returns true if test matches all patterns patternN.  Returns NULL if the expression on the left hand side is NULL or if one of the patterns in the list is NULL.</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFLikeAll</ClassName>
    </routine>
    <routine id="118" parent="1" name="likeany">
      <Comment>test likeany(pattern1, pattern2...) - returns true if test matches any patterns patternN. Returns NULL if the expression on the left hand side is NULL or if one of the patterns in the list is NULL.</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFLikeAny</ClassName>
    </routine>
    <routine id="119" parent="1" name="ln">
      <Comment>ln(x) - Returns the natural logarithm of x</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.UDFLn</ClassName>
    </routine>
    <routine id="120" parent="1" name="locate">
      <Comment>locate(substr, str[, pos]) - Returns the position of the first occurance of substr in str after position pos</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFLocate</ClassName>
    </routine>
    <routine id="121" parent="1" name="log">
      <Comment>log([b], x) - Returns the logarithm of x with base b</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.UDFLog</ClassName>
    </routine>
    <routine id="122" parent="1" name="log10">
      <Comment>log10(x) - Returns the logarithm of x with base 10</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.UDFLog10</ClassName>
    </routine>
    <routine id="123" parent="1" name="log2">
      <Comment>log2(x) - Returns the logarithm of x with base 2</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.UDFLog2</ClassName>
    </routine>
    <routine id="124" parent="1" name="logged_in_user">
      <Comment>logged_in_user() - Returns logged in user name</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFLoggedInUser</ClassName>
    </routine>
    <routine id="125" parent="1" name="lower">
      <Comment>lower(str) - Returns str with all characters changed to lowercase</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFLower</ClassName>
    </routine>
    <routine id="126" parent="1" name="lpad">
      <Comment>lpad(str, len, pad) - Returns str, left-padded with pad to a length of len</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFLpad</ClassName>
    </routine>
    <routine id="127" parent="1" name="ltrim">
      <Comment>ltrim(str) - Removes the leading space characters from str</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFLTrim</ClassName>
    </routine>
    <routine id="128" parent="1" name="map">
      <Comment>map(key0, value0, key1, value1...) - Creates a map with the given key/value pairs</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFMap</ClassName>
    </routine>
    <routine id="129" parent="1" name="map_keys">
      <Comment>map_keys(map) - Returns an unordered array containing the keys of the input map.</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFMapKeys</ClassName>
    </routine>
    <routine id="130" parent="1" name="map_values">
      <Comment>map_values(map) - Returns an unordered array containing the values of the input map.</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFMapValues</ClassName>
    </routine>
    <routine id="131" parent="1" name="mask">
      <Comment>masks the given value</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFMask</ClassName>
    </routine>
    <routine id="132" parent="1" name="mask_first_n">
      <Comment>masks the first n characters of the value</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFMaskFirstN</ClassName>
    </routine>
    <routine id="133" parent="1" name="mask_hash">
      <Comment>returns hash of the given value</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFMaskHash</ClassName>
    </routine>
    <routine id="134" parent="1" name="mask_last_n">
      <Comment>masks the last n characters of the value</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFMaskLastN</ClassName>
    </routine>
    <routine id="135" parent="1" name="mask_show_first_n">
      <Comment>masks all but first n characters of the value</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFMaskShowFirstN</ClassName>
    </routine>
    <routine id="136" parent="1" name="mask_show_last_n">
      <Comment>masks all but last n characters of the value</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFMaskShowLastN</ClassName>
    </routine>
    <routine id="137" parent="1" name="matchpath">
      <Comment>There is no documentation for function &apos;matchpath&apos;</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.ptf.MatchPath$MatchPathResolver</ClassName>
    </routine>
    <routine id="138" parent="1" name="max">
      <Comment>max(expr) - Returns the maximum value of expr</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDAFMax</ClassName>
    </routine>
    <routine id="139" parent="1" name="md5">
      <Comment>md5(str or bin) - Calculates an MD5 128-bit checksum for the string or binary.</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.UDFMd5</ClassName>
    </routine>
    <routine id="140" parent="1" name="min">
      <Comment>min(expr) - Returns the minimum value of expr</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDAFMin</ClassName>
    </routine>
    <routine id="141" parent="1" name="minute">
      <Comment>minute(param) - Returns the minute component of the string/timestamp/interval</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.UDFMinute</ClassName>
    </routine>
    <routine id="142" parent="1" name="mod">
      <Comment>a mod b - Returns the remainder when dividing a by b</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFOPMod</ClassName>
    </routine>
    <routine id="143" parent="1" name="month">
      <Comment>month(param) - Returns the month component of the date/timestamp/interval</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.UDFMonth</ClassName>
    </routine>
    <routine id="144" parent="1" name="months_between">
      <Comment>months_between(date1, date2, roundOff) - returns number of months between dates date1 and date2</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFMonthsBetween</ClassName>
    </routine>
    <routine id="145" parent="1" name="murmur_hash">
      <Comment>murmur_hash(a1, a2, ...) - Returns a hash value of the arguments</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFMurmurHash</ClassName>
    </routine>
    <routine id="146" parent="1" name="named_struct">
      <Comment>named_struct(name1, val1, name2, val2, ...) - Creates a struct with the given field names and values</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFNamedStruct</ClassName>
    </routine>
    <routine id="147" parent="1" name="negative">
      <Comment>negative a - Returns -a</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFOPNegative</ClassName>
    </routine>
    <routine id="148" parent="1" name="next_day">
      <Comment>next_day(start_date, day_of_week) - Returns the first date which is later than start_date and named as indicated.</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFNextDay</ClassName>
    </routine>
    <routine id="149" parent="1" name="ngrams">
      <Comment>ngrams(expr, n, k, pf) - Estimates the top-k n-grams in rows that consist of sequences of strings, represented as arrays of strings, or arrays of arrays of strings. &apos;pf&apos; is an optional precision factor that controls memory usage.</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDAFnGrams</ClassName>
    </routine>
    <routine id="150" parent="1" name="noop">
      <Comment>There is no documentation for function &apos;noop&apos;</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.ptf.Noop$NoopResolver</ClassName>
    </routine>
    <routine id="151" parent="1" name="noopstreaming">
      <Comment>There is no documentation for function &apos;noopstreaming&apos;</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.ptf.NoopStreaming$NoopStreamingResolver</ClassName>
    </routine>
    <routine id="152" parent="1" name="noopwithmap">
      <Comment>There is no documentation for function &apos;noopwithmap&apos;</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.ptf.NoopWithMap$NoopWithMapResolver</ClassName>
    </routine>
    <routine id="153" parent="1" name="noopwithmapstreaming">
      <Comment>There is no documentation for function &apos;noopwithmapstreaming&apos;</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.ptf.NoopWithMapStreaming$NoopWithMapStreamingResolver</ClassName>
    </routine>
    <routine id="154" parent="1" name="not">
      <Comment>not a - Logical not</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFOPNot</ClassName>
    </routine>
    <routine id="155" parent="1" name="ntile">
      <Comment>There is no documentation for function &apos;ntile&apos;</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDAFNTile</ClassName>
    </routine>
    <routine id="156" parent="1" name="nullif">
      <Comment>nullif(a1, a2) - shorthand for: case when a1 = a2 then null else a1</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFNullif</ClassName>
    </routine>
    <routine id="157" parent="1" name="nvl">
      <Comment>nvl(value,default_value) - Returns default value if value is null else returns value</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFNvl</ClassName>
    </routine>
    <routine id="158" parent="1" name="octet_length">
      <Comment>octet_length(str | binary) - Returns the number of bytes in str or binary data</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFOctetLength</ClassName>
    </routine>
    <routine id="159" parent="1" name="parse_url">
      <Comment>parse_url(url, partToExtract[, key]) - extracts a part from a URL</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.UDFParseUrl</ClassName>
    </routine>
    <routine id="160" parent="1" name="parse_url_tuple">
      <Comment>parse_url_tuple(url, partname1, partname2, ..., partnameN) - extracts N (N&gt;=1) parts from a URL.</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDTFParseUrlTuple</ClassName>
    </routine>
    <routine id="161" parent="1" name="percent_rank">
      <Comment>There is no documentation for function &apos;percent_rank&apos;</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDAFPercentRank</ClassName>
    </routine>
    <routine id="162" parent="1" name="percentile">
      <Comment>percentile(expr, pc) - Returns the percentile(s) of expr at pc (range: [0,1]).pc can be a double or double array</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.UDAFPercentile</ClassName>
    </routine>
    <routine id="163" parent="1" name="percentile_approx">
      <Comment>percentile_approx(expr, pc, [nb]) - For very large data, computes an approximate percentile value from a histogram, using the optional argument [nb] as the number of histogram bins to use. A higher value of nb results in a more accurate approximation, at the cost of higher memory usage.</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDAFPercentileApprox</ClassName>
    </routine>
    <routine id="164" parent="1" name="pi">
      <Comment>pi() - returns pi</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.UDFPI</ClassName>
    </routine>
    <routine id="165" parent="1" name="pmod">
      <Comment>a pmod b - Compute the positive modulo</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFPosMod</ClassName>
    </routine>
    <routine id="166" parent="1" name="posexplode">
      <Comment>posexplode(a) - behaves like explode for arrays, but includes the position of items in the original array</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDTFPosExplode</ClassName>
    </routine>
    <routine id="167" parent="1" name="positive">
      <Comment>positive a - Returns a</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFOPPositive</ClassName>
    </routine>
    <routine id="168" parent="1" name="pow">
      <Comment>pow(x1, x2) - raise x1 to the power of x2</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFPower</ClassName>
    </routine>
    <routine id="169" parent="1" name="power">
      <Comment>power(x1, x2) - raise x1 to the power of x2</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFPower</ClassName>
    </routine>
    <routine id="170" parent="1" name="printf">
      <Comment>printf(String format, Obj... args) - function that can format strings according to printf-style format strings</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFPrintf</ClassName>
    </routine>
    <routine id="171" parent="1" name="quarter">
      <Comment>quarter(date/timestamp/string) - Returns the quarter of the year for date, in the range 1 to 4.</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFQuarter</ClassName>
    </routine>
    <routine id="172" parent="1" name="radians">
      <Comment>radians(x) - Converts degrees to radians</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.UDFRadians</ClassName>
    </routine>
    <routine id="173" parent="1" name="rand">
      <Comment>rand([seed]) - Returns a pseudorandom number between 0 and 1</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.UDFRand</ClassName>
    </routine>
    <routine id="174" parent="1" name="rank">
      <Comment>There is no documentation for function &apos;rank&apos;</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDAFRank</ClassName>
    </routine>
    <routine id="175" parent="1" name="reflect">
      <Comment>reflect(class,method[,arg1[,arg2..]]) calls method with reflection</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFReflect</ClassName>
    </routine>
    <routine id="176" parent="1" name="reflect2">
      <Comment>reflect2(arg0,method[,arg1[,arg2..]]) calls method of arg0 with reflection</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFReflect2</ClassName>
    </routine>
    <routine id="177" parent="1" name="regexp_extract">
      <Comment>regexp_extract(str, regexp[, idx]) - extracts a group that matches regexp</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.UDFRegExpExtract</ClassName>
    </routine>
    <routine id="178" parent="1" name="regexp_replace">
      <Comment>regexp_replace(str, regexp, rep) - replace all substrings of str that match regexp with rep</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.UDFRegExpReplace</ClassName>
    </routine>
    <routine id="179" parent="1" name="regr_avgx">
      <Comment>regr_avgx(y,x) - evaluates the average of the independent variable</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDAFBinarySetFunctions$RegrAvgX</ClassName>
    </routine>
    <routine id="180" parent="1" name="regr_avgy">
      <Comment>regr_avgy(y,x) - evaluates the average of the dependent variable</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDAFBinarySetFunctions$RegrAvgY</ClassName>
    </routine>
    <routine id="181" parent="1" name="regr_count">
      <Comment>regr_count(y,x) - returns the number of non-null pairs</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDAFBinarySetFunctions$RegrCount</ClassName>
    </routine>
    <routine id="182" parent="1" name="regr_intercept">
      <Comment>regr_intercept(y,x) - returns the y-intercept of the regression line.</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDAFBinarySetFunctions$RegrIntercept</ClassName>
    </routine>
    <routine id="183" parent="1" name="regr_r2">
      <Comment>regr_r2(y,x) - returns the coefficient of determination (also called R-squared or goodness of fit) for the regression line.</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDAFBinarySetFunctions$RegrR2</ClassName>
    </routine>
    <routine id="184" parent="1" name="regr_slope">
      <Comment>regr_slope(y,x) - returns the slope of the linear regression line</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDAFBinarySetFunctions$RegrSlope</ClassName>
    </routine>
    <routine id="185" parent="1" name="regr_sxx">
      <Comment>regr_sxx(y,x) - auxiliary analytic function</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDAFBinarySetFunctions$RegrSXX</ClassName>
    </routine>
    <routine id="186" parent="1" name="regr_sxy">
      <Comment>regr_sxy(y,x) - return a value that can be used to evaluate the statistical validity of a regression model.</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDAFBinarySetFunctions$RegrSXY</ClassName>
    </routine>
    <routine id="187" parent="1" name="regr_syy">
      <Comment>regr_syy(y,x) - auxiliary analytic function</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDAFBinarySetFunctions$RegrSYY</ClassName>
    </routine>
    <routine id="188" parent="1" name="repeat">
      <Comment>repeat(str, n) - repeat str n times</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.UDFRepeat</ClassName>
    </routine>
    <routine id="189" parent="1" name="replace">
      <Comment>replace(str, search, rep) - replace all substrings of &apos;str&apos; that match &apos;search&apos; with &apos;rep&apos;</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.UDFReplace</ClassName>
    </routine>
    <routine id="190" parent="1" name="replicate_rows">
      <Comment>replicate_rows(n, cols...) - turns 1 row into n rows</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDTFReplicateRows</ClassName>
    </routine>
    <routine id="191" parent="1" name="restrict_information_schema">
      <Comment>restrict_information_schema() - Returns whether or not to enable information schema restriction. Currently it is enabled if either HS2 authorizer or metastore authorizer implements policy provider interface.</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFRestrictInformationSchema</ClassName>
    </routine>
    <routine id="192" parent="1" name="reverse">
      <Comment>reverse(str) - reverse str</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.UDFReverse</ClassName>
    </routine>
    <routine id="193" parent="1" name="round">
      <Comment>round(x[, d]) - round x to d decimal places</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFRound</ClassName>
    </routine>
    <routine id="194" parent="1" name="row_number">
      <Comment>There is no documentation for function &apos;row_number&apos;</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDAFRowNumber</ClassName>
    </routine>
    <routine id="195" parent="1" name="rpad">
      <Comment>rpad(str, len, pad) - Returns str, right-padded with pad to a length of len</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFRpad</ClassName>
    </routine>
    <routine id="196" parent="1" name="rtrim">
      <Comment>rtrim(str) - Removes the trailing space characters from str</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFRTrim</ClassName>
    </routine>
    <routine id="197" parent="1" name="second">
      <Comment>second(date) - Returns the second component of the string/timestamp/interval</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.UDFSecond</ClassName>
    </routine>
    <routine id="198" parent="1" name="sentences">
      <Comment>sentences(str, lang, country) - Splits str into arrays of sentences, where each sentence is an array of words. The &apos;lang&apos; and&apos;country&apos; arguments are optional, and if omitted, the default locale is used.</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFSentences</ClassName>
    </routine>
    <routine id="199" parent="1" name="sha">
      <Comment>sha(str or bin) - Calculates the SHA-1 digest for string or binary and returns the value as a hex string.</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.UDFSha1</ClassName>
    </routine>
    <routine id="200" parent="1" name="sha1">
      <Comment>sha1(str or bin) - Calculates the SHA-1 digest for string or binary and returns the value as a hex string.</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.UDFSha1</ClassName>
    </routine>
    <routine id="201" parent="1" name="sha2">
      <Comment>sha2(string/binary, len) - Calculates the SHA-2 family of hash functions (SHA-224, SHA-256, SHA-384, and SHA-512).</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFSha2</ClassName>
    </routine>
    <routine id="202" parent="1" name="shiftleft">
      <Comment>shiftleft(a, b) - Bitwise left shift</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.UDFOPBitShiftLeft</ClassName>
    </routine>
    <routine id="203" parent="1" name="shiftright">
      <Comment>shiftright(a, b) - Bitwise right shift</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.UDFOPBitShiftRight</ClassName>
    </routine>
    <routine id="204" parent="1" name="shiftrightunsigned">
      <Comment>shiftrightunsigned(a, b) - Bitwise unsigned right shift</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.UDFOPBitShiftRightUnsigned</ClassName>
    </routine>
    <routine id="205" parent="1" name="sign">
      <Comment>sign(x) - returns the sign of x )</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.UDFSign</ClassName>
    </routine>
    <routine id="206" parent="1" name="sin">
      <Comment>sin(x) - returns the sine of x (x is in radians)</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.UDFSin</ClassName>
    </routine>
    <routine id="207" parent="1" name="size">
      <Comment>size(a) - Returns the size of a</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFSize</ClassName>
    </routine>
    <routine id="208" parent="1" name="sort_array">
      <Comment>sort_array(array(obj1, obj2,...)) - Sorts the input array in ascending order according to the natural ordering of the array elements.</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFSortArray</ClassName>
    </routine>
    <routine id="209" parent="1" name="sort_array_by">
      <Comment>sort_array_by(array(obj1, obj2,...),&apos;f1&apos;,&apos;f2&apos;,...,[&apos;ASC&apos;,&apos;DESC&apos;]) - Sorts the input tuple array in user specified order(ASC,DESC) by desired field[s] name If sorting order is not mentioned by user then dafault sorting order is ascending</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFSortArrayByField</ClassName>
    </routine>
    <routine id="210" parent="1" name="soundex">
      <Comment>soundex(string) - Returns soundex code of the string.</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFSoundex</ClassName>
    </routine>
    <routine id="211" parent="1" name="space">
      <Comment>space(n) - returns n spaces</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.UDFSpace</ClassName>
    </routine>
    <routine id="212" parent="1" name="split">
      <Comment>split(str, regex) - Splits str around occurances that match regex</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFSplit</ClassName>
    </routine>
    <routine id="213" parent="1" name="sq_count_check">
      <Comment>sq_count_check(x) - Internal check on scalar subquery expression to make sure atmost one row is returned</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFSQCountCheck</ClassName>
    </routine>
    <routine id="214" parent="1" name="sqrt">
      <Comment>sqrt(x) - returns the square root of x</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.UDFSqrt</ClassName>
    </routine>
    <routine id="215" parent="1" name="stack">
      <Comment>stack(n, cols...) - turns k columns into n rows of size k/n each</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDTFStack</ClassName>
    </routine>
    <routine id="216" parent="1" name="std">
      <Comment>std(x) - Returns the standard deviation of a set of numbers</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDAFStd</ClassName>
    </routine>
    <routine id="217" parent="1" name="stddev">
      <Comment>stddev(x) - Returns the standard deviation of a set of numbers</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDAFStd</ClassName>
    </routine>
    <routine id="218" parent="1" name="stddev_pop">
      <Comment>stddev_pop(x) - Returns the standard deviation of a set of numbers</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDAFStd</ClassName>
    </routine>
    <routine id="219" parent="1" name="stddev_samp">
      <Comment>stddev_samp(x) - Returns the sample standard deviation of a set of numbers.</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDAFStdSample</ClassName>
    </routine>
    <routine id="220" parent="1" name="str_to_map">
      <Comment>str_to_map(text, delimiter1, delimiter2) - Creates a map by parsing text</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFStringToMap</ClassName>
    </routine>
    <routine id="221" parent="1" name="struct">
      <Comment>struct(col1, col2, col3, ...) - Creates a struct with the given field values</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFStruct</ClassName>
    </routine>
    <routine id="222" parent="1" name="substr">
      <Comment>substr(str, pos[, len]) - returns the substring of str that starts at pos and is of length len orsubstr(bin, pos[, len]) - returns the slice of byte array that starts at pos and is of length len</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.UDFSubstr</ClassName>
    </routine>
    <routine id="223" parent="1" name="substring">
      <Comment>substring(str, pos[, len]) - returns the substring of str that starts at pos and is of length len orsubstring(bin, pos[, len]) - returns the slice of byte array that starts at pos and is of length len</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.UDFSubstr</ClassName>
    </routine>
    <routine id="224" parent="1" name="substring_index">
      <Comment>substring_index(str, delim, count) - Returns the substring from string str before count occurrences of the delimiter delim.</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFSubstringIndex</ClassName>
    </routine>
    <routine id="225" parent="1" name="sum">
      <Comment>sum(x) - Returns the sum of a set of numbers</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDAFSum</ClassName>
    </routine>
    <routine id="226" parent="1" name="tan">
      <Comment>tan(x) - returns the tangent of x (x is in radians)</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.UDFTan</ClassName>
    </routine>
    <routine id="227" parent="1" name="to_date">
      <Comment>to_date(expr) - Extracts the date part of the date or datetime expression expr</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFDate</ClassName>
    </routine>
    <routine id="228" parent="1" name="to_epoch_milli">
      <Comment>There is no documentation for function &apos;to_epoch_milli&apos;</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFEpochMilli</ClassName>
    </routine>
    <routine id="229" parent="1" name="to_unix_timestamp">
      <Comment>to_unix_timestamp(date[, pattern]) - Returns the UNIX timestamp</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFToUnixTimeStamp</ClassName>
    </routine>
    <routine id="230" parent="1" name="to_utc_timestamp">
      <Comment>to_utc_timestamp(timestamp, string timezone) - Assumes given timestamp is in given timezone and converts to UTC (as of Hive 0.8.0)</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFToUtcTimestamp</ClassName>
    </routine>
    <routine id="231" parent="1" name="translate">
      <Comment>translate(input, from, to) - translates the input string by replacing the characters present in the from string with the corresponding characters in the to string</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFTranslate</ClassName>
    </routine>
    <routine id="232" parent="1" name="trim">
      <Comment>trim(str) - Removes the leading and trailing space characters from str</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFTrim</ClassName>
    </routine>
    <routine id="233" parent="1" name="trunc">
      <Comment>trunc(date, fmt) / trunc(N,D) - Returns If input is date returns date with the time portion of the day truncated to the unit specified by the format model fmt. If you omit fmt, then date is truncated to the nearest day. It currently only supports &apos;MONTH&apos;/&apos;MON&apos;/&apos;MM&apos;, &apos;QUARTER&apos;/&apos;Q&apos; and &apos;YEAR&apos;/&apos;YYYY&apos;/&apos;YY&apos; as format.If input is a number group returns N truncated to D decimal places. If D is omitted, then N is truncated to 0 places.D can be negative to truncate (make zero) D digits left of the decimal point.</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFTrunc</ClassName>
    </routine>
    <routine id="234" parent="1" name="ucase">
      <Comment>ucase(str) - Returns str with all characters changed to uppercase</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFUpper</ClassName>
    </routine>
    <routine id="235" parent="1" name="udftoboolean">
      <Comment>There is no documentation for function &apos;udftoboolean&apos;</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.UDFToBoolean</ClassName>
    </routine>
    <routine id="236" parent="1" name="udftobyte">
      <Comment>There is no documentation for function &apos;udftobyte&apos;</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.UDFToByte</ClassName>
    </routine>
    <routine id="237" parent="1" name="udftodouble">
      <Comment>There is no documentation for function &apos;udftodouble&apos;</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.UDFToDouble</ClassName>
    </routine>
    <routine id="238" parent="1" name="udftofloat">
      <Comment>There is no documentation for function &apos;udftofloat&apos;</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.UDFToFloat</ClassName>
    </routine>
    <routine id="239" parent="1" name="udftointeger">
      <Comment>There is no documentation for function &apos;udftointeger&apos;</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.UDFToInteger</ClassName>
    </routine>
    <routine id="240" parent="1" name="udftolong">
      <Comment>There is no documentation for function &apos;udftolong&apos;</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.UDFToLong</ClassName>
    </routine>
    <routine id="241" parent="1" name="udftoshort">
      <Comment>There is no documentation for function &apos;udftoshort&apos;</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.UDFToShort</ClassName>
    </routine>
    <routine id="242" parent="1" name="udftostring">
      <Comment>There is no documentation for function &apos;udftostring&apos;</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.UDFToString</ClassName>
    </routine>
    <routine id="243" parent="1" name="unbase64">
      <Comment>unbase64(str) - Convert the argument from a base 64 string to binary</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.UDFUnbase64</ClassName>
    </routine>
    <routine id="244" parent="1" name="unhex">
      <Comment>unhex(str) - Converts hexadecimal argument to binary</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.UDFUnhex</ClassName>
    </routine>
    <routine id="245" parent="1" name="unix_timestamp">
      <Comment>unix_timestamp(date[, pattern]) - Converts the time to a number</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFUnixTimeStamp</ClassName>
    </routine>
    <routine id="246" parent="1" name="upper">
      <Comment>upper(str) - Returns str with all characters changed to uppercase</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFUpper</ClassName>
    </routine>
    <routine id="247" parent="1" name="uuid">
      <Comment>uuid() - Returns a universally unique identifier (UUID) string.</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.UDFUUID</ClassName>
    </routine>
    <routine id="248" parent="1" name="var_pop">
      <Comment>var_pop(x) - Returns the variance of a set of numbers</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDAFVariance</ClassName>
    </routine>
    <routine id="249" parent="1" name="var_samp">
      <Comment>var_samp(x) - Returns the sample variance of a set of numbers.</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDAFVarianceSample</ClassName>
    </routine>
    <routine id="250" parent="1" name="variance">
      <Comment>variance(x) - Returns the variance of a set of numbers</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDAFVariance</ClassName>
    </routine>
    <routine id="251" parent="1" name="version">
      <Comment>version() - Returns the Hive build version string - includes base version and revision.</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.UDFVersion</ClassName>
    </routine>
    <routine id="252" parent="1" name="weekofyear">
      <Comment>weekofyear(date) - Returns the week of the year of the given date. A week is considered to start on a Monday and week 1 is the first week with &gt;3 days.</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.UDFWeekOfYear</ClassName>
    </routine>
    <routine id="253" parent="1" name="width_bucket">
      <Comment>width_bucket(expr, min_value, max_value, num_buckets) - Returns an integer between 0 and num_buckets+1 by mapping the expr into buckets defined by the range [min_value, max_value]</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.generic.GenericUDFWidthBucket</ClassName>
    </routine>
    <routine id="254" parent="1" name="windowingtablefunction">
      <Comment>There is no documentation for function &apos;windowingtablefunction&apos;</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.ptf.WindowingTableFunction$WindowingTableFunctionResolver</ClassName>
    </routine>
    <routine id="255" parent="1" name="xpath">
      <Comment>xpath(xml, xpath) - Returns a string array of values within xml nodes that match the xpath expression</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.xml.GenericUDFXPath</ClassName>
    </routine>
    <routine id="256" parent="1" name="xpath_boolean">
      <Comment>xpath_boolean(xml, xpath) - Evaluates a boolean xpath expression</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.xml.UDFXPathBoolean</ClassName>
    </routine>
    <routine id="257" parent="1" name="xpath_double">
      <Comment>xpath_double(xml, xpath) - Returns a double value that matches the xpath expression</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.xml.UDFXPathDouble</ClassName>
    </routine>
    <routine id="258" parent="1" name="xpath_float">
      <Comment>xpath_float(xml, xpath) - Returns a float value that matches the xpath expression</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.xml.UDFXPathFloat</ClassName>
    </routine>
    <routine id="259" parent="1" name="xpath_int">
      <Comment>xpath_int(xml, xpath) - Returns an integer value that matches the xpath expression</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.xml.UDFXPathInteger</ClassName>
    </routine>
    <routine id="260" parent="1" name="xpath_long">
      <Comment>xpath_long(xml, xpath) - Returns a long value that matches the xpath expression</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.xml.UDFXPathLong</ClassName>
    </routine>
    <routine id="261" parent="1" name="xpath_number">
      <Comment>xpath_number(xml, xpath) - Returns a double value that matches the xpath expression</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.xml.UDFXPathDouble</ClassName>
    </routine>
    <routine id="262" parent="1" name="xpath_short">
      <Comment>xpath_short(xml, xpath) - Returns a short value that matches the xpath expression</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.xml.UDFXPathShort</ClassName>
    </routine>
    <routine id="263" parent="1" name="xpath_string">
      <Comment>xpath_string(xml, xpath) - Returns the text contents of the first xml node that matches the xpath expression</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.xml.UDFXPathString</ClassName>
    </routine>
    <routine id="264" parent="1" name="year">
      <Comment>year(param) - Returns the year component of the date/timestamp/interval</Comment>
      <ClassName>org.apache.hadoop.hive.ql.udf.UDFYear</ClassName>
    </routine>
    <table id="265" parent="2" name="city_info"/>
    <table id="266" parent="2" name="product_info"/>
    <table id="267" parent="2" name="user_visit_action"/>
    <table id="268" parent="3" name="aa">
      <Properties>spark.sql.create.version
2.4.5
spark.sql.sources.schema.numParts
1
spark.sql.sources.schema.part.0
{&quot;type&quot;:&quot;struct&quot;,&quot;fields&quot;:[{&quot;name&quot;:&quot;id&quot;,&quot;type&quot;:&quot;integer&quot;,&quot;nullable&quot;:true,&quot;metadata&quot;:{}}]}
transient_lastDdlTime
1591950522</Properties>
      <RowFormatSerde>org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</RowFormatSerde>
      <InputFormat>org.apache.hadoop.mapred.TextInputFormat</InputFormat>
      <OutputFormat>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</OutputFormat>
      <Location>hdfs://hadoop102:8020/user/hive/warehouse/aa</Location>
    </table>
    <table id="269" parent="3" name="action">
      <Properties>bucketing_version
2
transient_lastDdlTime
1588076749</Properties>
      <RowFormatSerde>org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</RowFormatSerde>
      <SerdeProperties>field.delim
\t
serialization.format
\t</SerdeProperties>
      <InputFormat>org.apache.hadoop.mapred.TextInputFormat</InputFormat>
      <OutputFormat>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</OutputFormat>
      <Location>hdfs://hadoop102:8020/user/hive/warehouse/action</Location>
    </table>
    <table id="270" parent="3" name="business">
      <Properties>bucketing_version
2
transient_lastDdlTime
1587988481</Properties>
      <RowFormatSerde>org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</RowFormatSerde>
      <SerdeProperties>field.delim
,
serialization.format
,</SerdeProperties>
      <InputFormat>org.apache.hadoop.mapred.TextInputFormat</InputFormat>
      <OutputFormat>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</OutputFormat>
      <Location>hdfs://hadoop102:8020/user/hive/warehouse/business</Location>
    </table>
    <table id="271" parent="3" name="dept">
      <Properties>bucketing_version
2
transient_lastDdlTime
1587908251</Properties>
      <RowFormatSerde>org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</RowFormatSerde>
      <SerdeProperties>field.delim
\t
serialization.format
\t</SerdeProperties>
      <InputFormat>org.apache.hadoop.mapred.TextInputFormat</InputFormat>
      <OutputFormat>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</OutputFormat>
      <Location>hdfs://hadoop102:8020/user/hive/warehouse/dept</Location>
    </table>
    <table id="272" parent="3" name="dept_pa">
      <Properties>bucketing_version
2
transient_lastDdlTime
1587956109</Properties>
      <RowFormatSerde>org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</RowFormatSerde>
      <SerdeProperties>field.delim
\t
serialization.format
\t</SerdeProperties>
      <InputFormat>org.apache.hadoop.mapred.TextInputFormat</InputFormat>
      <OutputFormat>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</OutputFormat>
      <Location>hdfs://hadoop102:8020/user/hive/warehouse/dept_pa</Location>
    </table>
    <table id="273" parent="3" name="emp">
      <Properties>bucketing_version
2
transient_lastDdlTime
1587908455</Properties>
      <RowFormatSerde>org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</RowFormatSerde>
      <SerdeProperties>field.delim
\t
serialization.format
\t</SerdeProperties>
      <InputFormat>org.apache.hadoop.mapred.TextInputFormat</InputFormat>
      <OutputFormat>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</OutputFormat>
      <Location>hdfs://hadoop102:8020/user/hive/warehouse/emp</Location>
    </table>
    <table id="274" parent="3" name="emp_sex">
      <Properties>bucketing_version
2
transient_lastDdlTime
1587986810</Properties>
      <RowFormatSerde>org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</RowFormatSerde>
      <SerdeProperties>field.delim
\t
serialization.format
\t</SerdeProperties>
      <InputFormat>org.apache.hadoop.mapred.TextInputFormat</InputFormat>
      <OutputFormat>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</OutputFormat>
      <Location>hdfs://hadoop102:8020/user/hive/warehouse/emp_sex</Location>
    </table>
    <table id="275" parent="3" name="gulivideo_orc">
      <Properties>bucketing_version
2
transient_lastDdlTime
1587914822</Properties>
      <RowFormatSerde>org.apache.hadoop.hive.ql.io.orc.OrcSerde</RowFormatSerde>
      <SerdeProperties>collection.delim
&amp;
field.delim
\t
serialization.format
\t</SerdeProperties>
      <InputFormat>org.apache.hadoop.hive.ql.io.orc.OrcInputFormat</InputFormat>
      <OutputFormat>org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat</OutputFormat>
      <Location>hdfs://hadoop102:8020/user/hive/warehouse/gulivideo_orc</Location>
    </table>
    <table id="276" parent="3" name="gulivideo_ori">
      <Properties>bucketing_version
2
transient_lastDdlTime
1587914677</Properties>
      <RowFormatSerde>org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</RowFormatSerde>
      <SerdeProperties>collection.delim
&amp;
field.delim
\t
serialization.format
\t</SerdeProperties>
      <InputFormat>org.apache.hadoop.mapred.TextInputFormat</InputFormat>
      <OutputFormat>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</OutputFormat>
      <Location>hdfs://hadoop102:8020/user/hive/warehouse/gulivideo_ori</Location>
    </table>
    <table id="277" parent="3" name="gulivideo_user_orc">
      <Properties>bucketing_version
2
transient_lastDdlTime
1587914842</Properties>
      <RowFormatSerde>org.apache.hadoop.hive.ql.io.orc.OrcSerde</RowFormatSerde>
      <SerdeProperties>field.delim
\t
serialization.format
\t</SerdeProperties>
      <InputFormat>org.apache.hadoop.hive.ql.io.orc.OrcInputFormat</InputFormat>
      <OutputFormat>org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat</OutputFormat>
      <Location>hdfs://hadoop102:8020/user/hive/warehouse/gulivideo_user_orc</Location>
    </table>
    <table id="278" parent="3" name="gulivideo_user_ori">
      <Properties>bucketing_version
2
transient_lastDdlTime
1587914726</Properties>
      <RowFormatSerde>org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</RowFormatSerde>
      <SerdeProperties>field.delim
\t
serialization.format
\t</SerdeProperties>
      <InputFormat>org.apache.hadoop.mapred.TextInputFormat</InputFormat>
      <OutputFormat>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</OutputFormat>
      <Location>hdfs://hadoop102:8020/user/hive/warehouse/gulivideo_user_ori</Location>
    </table>
    <table id="279" parent="3" name="kylin_intermediate_dd_8f86bb1d_468f_9382_3931_273265e926e0">
      <Properties>auto.purge
true
bucketing_version
2
last_modified_by
atguigu
last_modified_time
1588953813
transient_lastDdlTime
1588953859</Properties>
      <RowFormatSerde>org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</RowFormatSerde>
      <InputFormat>org.apache.hadoop.mapred.SequenceFileInputFormat</InputFormat>
      <OutputFormat>org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat</OutputFormat>
      <Location>hdfs://hadoop102:8020/kylin/kylin_metadata/kylin-99a469d3-6b2b-6145-6b7f-37199fdbc39a/kylin_intermediate_dd_8f86bb1d_468f_9382_3931_273265e926e0</Location>
    </table>
    <table id="280" parent="3" name="kylin_intermediate_dd_bfc263f2_2f75_158c_72e6_62a9cad67e0e">
      <Properties>auto.purge
true
bucketing_version
2
last_modified_by
atguigu
last_modified_time
1588954148
transient_lastDdlTime
1588954222</Properties>
      <RowFormatSerde>org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</RowFormatSerde>
      <InputFormat>org.apache.hadoop.mapred.SequenceFileInputFormat</InputFormat>
      <OutputFormat>org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat</OutputFormat>
      <Location>hdfs://hadoop102:8020/kylin/kylin_metadata/kylin-bc5f7d0c-ea05-397f-ea4e-6ec6f31ad375/kylin_intermediate_dd_bfc263f2_2f75_158c_72e6_62a9cad67e0e</Location>
    </table>
    <table id="281" parent="3" name="kylin_intermediate_default_user_info_view_009c4c4f_9f82_4247_5150_90b53fa050db">
      <Properties>auto.purge
true
bucketing_version
2
last_modified_by
atguigu
last_modified_time
1588944690
transient_lastDdlTime
1588944715</Properties>
      <RowFormatSerde>org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</RowFormatSerde>
      <InputFormat>org.apache.hadoop.mapred.TextInputFormat</InputFormat>
      <OutputFormat>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</OutputFormat>
      <Location>hdfs://hadoop102:8020/user/hive/warehouse/kylin_intermediate_default_user_info_view_009c4c4f_9f82_4247_5150_90b53fa050db</Location>
    </table>
    <table id="282" parent="3" name="kylin_intermediate_default_user_info_view_862e1ace_b38b_0434_2402_13d43f4a912b">
      <Properties>auto.purge
true
bucketing_version
2
last_modified_by
atguigu
last_modified_time
1588942942
transient_lastDdlTime
1588942956</Properties>
      <RowFormatSerde>org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</RowFormatSerde>
      <InputFormat>org.apache.hadoop.mapred.TextInputFormat</InputFormat>
      <OutputFormat>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</OutputFormat>
      <Location>hdfs://hadoop102:8020/user/hive/warehouse/kylin_intermediate_default_user_info_view_862e1ace_b38b_0434_2402_13d43f4a912b</Location>
    </table>
    <table id="283" parent="3" name="kylin_intermediate_default_user_info_view_95ba7718_b4bc_4c6b_cae9_62bb6265011f">
      <Properties>auto.purge
true
bucketing_version
2
last_modified_by
atguigu
last_modified_time
1588953362
transient_lastDdlTime
1588953447</Properties>
      <RowFormatSerde>org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</RowFormatSerde>
      <InputFormat>org.apache.hadoop.mapred.TextInputFormat</InputFormat>
      <OutputFormat>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</OutputFormat>
      <Location>hdfs://hadoop102:8020/user/hive/warehouse/kylin_intermediate_default_user_info_view_95ba7718_b4bc_4c6b_cae9_62bb6265011f</Location>
    </table>
    <table id="284" parent="3" name="kylin_intermediate_default_user_info_view_99a469d3_6b2b_6145_6b7f_37199fdbc39a">
      <Properties>auto.purge
true
bucketing_version
2
last_modified_by
atguigu
last_modified_time
1588953869
transient_lastDdlTime
1588953887</Properties>
      <RowFormatSerde>org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</RowFormatSerde>
      <InputFormat>org.apache.hadoop.mapred.TextInputFormat</InputFormat>
      <OutputFormat>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</OutputFormat>
      <Location>hdfs://hadoop102:8020/user/hive/warehouse/kylin_intermediate_default_user_info_view_99a469d3_6b2b_6145_6b7f_37199fdbc39a</Location>
    </table>
    <table id="285" parent="3" name="kylin_intermediate_default_user_info_view_a01b0d54_1074_0a42_924b_2f0ddd9fd158">
      <Properties>auto.purge
true
bucketing_version
2
last_modified_by
atguigu
last_modified_time
1588949747
transient_lastDdlTime
1588949763</Properties>
      <RowFormatSerde>org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</RowFormatSerde>
      <InputFormat>org.apache.hadoop.mapred.TextInputFormat</InputFormat>
      <OutputFormat>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</OutputFormat>
      <Location>hdfs://hadoop102:8020/user/hive/warehouse/kylin_intermediate_default_user_info_view_a01b0d54_1074_0a42_924b_2f0ddd9fd158</Location>
    </table>
    <table id="286" parent="3" name="kylin_intermediate_default_user_info_view_bc5f7d0c_ea05_397f_ea4e_6ec6f31ad375">
      <Properties>auto.purge
true
bucketing_version
2
last_modified_by
atguigu
last_modified_time
1588954231
transient_lastDdlTime
1588954408</Properties>
      <RowFormatSerde>org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</RowFormatSerde>
      <InputFormat>org.apache.hadoop.mapred.TextInputFormat</InputFormat>
      <OutputFormat>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</OutputFormat>
      <Location>hdfs://hadoop102:8020/user/hive/warehouse/kylin_intermediate_default_user_info_view_bc5f7d0c_ea05_397f_ea4e_6ec6f31ad375</Location>
    </table>
    <table id="287" parent="3" name="kylin_intermediate_payment_cube_4c8fe289_e044_7151_babf_2a50098e34b4">
      <Properties>auto.purge
true
bucketing_version
2
last_modified_by
atguigu
last_modified_time
1588941986
transient_lastDdlTime
1588942031</Properties>
      <RowFormatSerde>org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</RowFormatSerde>
      <InputFormat>org.apache.hadoop.mapred.SequenceFileInputFormat</InputFormat>
      <OutputFormat>org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat</OutputFormat>
      <Location>hdfs://hadoop102:8020/kylin/kylin_metadata/kylin-9b8083f1-d10e-1464-dc74-fd34b664cc17/kylin_intermediate_payment_cube_4c8fe289_e044_7151_babf_2a50098e34b4</Location>
    </table>
    <table id="288" parent="3" name="kylin_intermediate_payment_star_2c768974_4f3e_6d0e_5e88_148d64c077db">
      <Properties>auto.purge
true
bucketing_version
2
last_modified_by
atguigu
last_modified_time
1588953300
transient_lastDdlTime
1588953353</Properties>
      <RowFormatSerde>org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</RowFormatSerde>
      <InputFormat>org.apache.hadoop.mapred.SequenceFileInputFormat</InputFormat>
      <OutputFormat>org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat</OutputFormat>
      <Location>hdfs://hadoop102:8020/kylin/kylin_metadata/kylin-95ba7718-b4bc-4c6b-cae9-62bb6265011f/kylin_intermediate_payment_star_2c768974_4f3e_6d0e_5e88_148d64c077db</Location>
    </table>
    <table id="289" parent="3" name="kylin_intermediate_payment_star_a9eb7167_b8ea_2140_00e5_6591c10d73c8">
      <Properties>auto.purge
true
bucketing_version
2
last_modified_by
atguigu
last_modified_time
1588942884
transient_lastDdlTime
1588942933</Properties>
      <RowFormatSerde>org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</RowFormatSerde>
      <InputFormat>org.apache.hadoop.mapred.SequenceFileInputFormat</InputFormat>
      <OutputFormat>org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat</OutputFormat>
      <Location>hdfs://hadoop102:8020/kylin/kylin_metadata/kylin-862e1ace-b38b-0434-2402-13d43f4a912b/kylin_intermediate_payment_star_a9eb7167_b8ea_2140_00e5_6591c10d73c8</Location>
    </table>
    <table id="290" parent="3" name="kylin_intermediate_payment_star_b8e415fb_8291_4f08_eeef_aff11ae9532f">
      <Properties>auto.purge
true
bucketing_version
2
last_modified_by
atguigu
last_modified_time
1588949678
transient_lastDdlTime
1588949735</Properties>
      <RowFormatSerde>org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</RowFormatSerde>
      <InputFormat>org.apache.hadoop.mapred.SequenceFileInputFormat</InputFormat>
      <OutputFormat>org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat</OutputFormat>
      <Location>hdfs://hadoop102:8020/kylin/kylin_metadata/kylin-a01b0d54-1074-0a42-924b-2f0ddd9fd158/kylin_intermediate_payment_star_b8e415fb_8291_4f08_eeef_aff11ae9532f</Location>
    </table>
    <table id="291" parent="3" name="kylin_intermediate_payment_star_bd0ea62c_383b_7bbc_9f3b_361d2dcf751b">
      <Properties>auto.purge
true
bucketing_version
2
last_modified_by
atguigu
last_modified_time
1588944628
transient_lastDdlTime
1588944678</Properties>
      <RowFormatSerde>org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</RowFormatSerde>
      <InputFormat>org.apache.hadoop.mapred.SequenceFileInputFormat</InputFormat>
      <OutputFormat>org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat</OutputFormat>
      <Location>hdfs://hadoop102:8020/kylin/kylin_metadata/kylin-009c4c4f-9f82-4247-5150-90b53fa050db/kylin_intermediate_payment_star_bd0ea62c_383b_7bbc_9f3b_361d2dcf751b</Location>
    </table>
    <table id="292" parent="3" name="log_orc">
      <Properties>bucketing_version
2
orc.compress
NONE
transient_lastDdlTime
1588075872</Properties>
      <RowFormatSerde>org.apache.hadoop.hive.ql.io.orc.OrcSerde</RowFormatSerde>
      <SerdeProperties>field.delim
\t
serialization.format
\t</SerdeProperties>
      <InputFormat>org.apache.hadoop.hive.ql.io.orc.OrcInputFormat</InputFormat>
      <OutputFormat>org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat</OutputFormat>
      <Location>hdfs://hadoop102:8020/user/hive/warehouse/log_orc</Location>
    </table>
    <table id="293" parent="3" name="log_orc_snappy">
      <Properties>bucketing_version
2
orc.compress
SNAPPY
transient_lastDdlTime
1588076033</Properties>
      <RowFormatSerde>org.apache.hadoop.hive.ql.io.orc.OrcSerde</RowFormatSerde>
      <SerdeProperties>field.delim
\t
serialization.format
\t</SerdeProperties>
      <InputFormat>org.apache.hadoop.hive.ql.io.orc.OrcInputFormat</InputFormat>
      <OutputFormat>org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat</OutputFormat>
      <Location>hdfs://hadoop102:8020/user/hive/warehouse/log_orc_snappy</Location>
    </table>
    <table id="294" parent="3" name="log_orc_zlib">
      <Properties>bucketing_version
2
orc.compress
ZLIB
transient_lastDdlTime
1588075978</Properties>
      <RowFormatSerde>org.apache.hadoop.hive.ql.io.orc.OrcSerde</RowFormatSerde>
      <SerdeProperties>field.delim
\t
serialization.format
\t</SerdeProperties>
      <InputFormat>org.apache.hadoop.hive.ql.io.orc.OrcInputFormat</InputFormat>
      <OutputFormat>org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat</OutputFormat>
      <Location>hdfs://hadoop102:8020/user/hive/warehouse/log_orc_zlib</Location>
    </table>
    <table id="295" parent="3" name="log_parquet">
      <Properties>bucketing_version
2
transient_lastDdlTime
1588075909</Properties>
      <RowFormatSerde>org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe</RowFormatSerde>
      <SerdeProperties>field.delim
\t
serialization.format
\t</SerdeProperties>
      <InputFormat>org.apache.hadoop.hive.ql.io.parquet.MapredParquetInputFormat</InputFormat>
      <OutputFormat>org.apache.hadoop.hive.ql.io.parquet.MapredParquetOutputFormat</OutputFormat>
      <Location>hdfs://hadoop102:8020/user/hive/warehouse/log_parquet</Location>
    </table>
    <table id="296" parent="3" name="log_parquet_snappy">
      <Properties>bucketing_version
2
parquet.compression
SNAPPY
transient_lastDdlTime
1588076080</Properties>
      <RowFormatSerde>org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe</RowFormatSerde>
      <SerdeProperties>field.delim
\t
serialization.format
\t</SerdeProperties>
      <InputFormat>org.apache.hadoop.hive.ql.io.parquet.MapredParquetInputFormat</InputFormat>
      <OutputFormat>org.apache.hadoop.hive.ql.io.parquet.MapredParquetOutputFormat</OutputFormat>
      <Location>hdfs://hadoop102:8020/user/hive/warehouse/log_parquet_snappy</Location>
    </table>
    <table id="297" parent="3" name="log_text">
      <Properties>bucketing_version
2
transient_lastDdlTime
1588075717</Properties>
      <RowFormatSerde>org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</RowFormatSerde>
      <SerdeProperties>field.delim
\t
serialization.format
\t</SerdeProperties>
      <InputFormat>org.apache.hadoop.mapred.TextInputFormat</InputFormat>
      <OutputFormat>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</OutputFormat>
      <Location>hdfs://hadoop102:8020/user/hive/warehouse/log_text</Location>
    </table>
    <table id="298" parent="3" name="movie_info">
      <Properties>bucketing_version
2
transient_lastDdlTime
1587988060</Properties>
      <RowFormatSerde>org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</RowFormatSerde>
      <SerdeProperties>field.delim
\t
serialization.format
\t</SerdeProperties>
      <InputFormat>org.apache.hadoop.mapred.TextInputFormat</InputFormat>
      <OutputFormat>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</OutputFormat>
      <Location>hdfs://hadoop102:8020/user/hive/warehouse/movie_info</Location>
    </table>
    <table id="299" parent="3" name="payment_info">
      <Properties>bucketing_version
2
transient_lastDdlTime
1588938242</Properties>
      <RowFormatSerde>org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</RowFormatSerde>
      <SerdeProperties>field.delim
\t
serialization.format
\t</SerdeProperties>
      <InputFormat>org.apache.hadoop.mapred.TextInputFormat</InputFormat>
      <OutputFormat>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</OutputFormat>
      <Location>hdfs://hadoop102:8020/user/hive/warehouse/payment_info</Location>
    </table>
    <table id="300" parent="3" name="person_info">
      <Properties>bucketing_version
2
transient_lastDdlTime
1587987540</Properties>
      <RowFormatSerde>org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</RowFormatSerde>
      <SerdeProperties>field.delim
\t
serialization.format
\t</SerdeProperties>
      <InputFormat>org.apache.hadoop.mapred.TextInputFormat</InputFormat>
      <OutputFormat>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</OutputFormat>
      <Location>hdfs://hadoop102:8020/user/hive/warehouse/person_info</Location>
    </table>
    <table id="301" parent="3" name="score">
      <Properties>bucketing_version
2
transient_lastDdlTime
1591880483</Properties>
      <RowFormatSerde>org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</RowFormatSerde>
      <SerdeProperties>field.delim
\t
serialization.format
\t</SerdeProperties>
      <InputFormat>org.apache.hadoop.mapred.TextInputFormat</InputFormat>
      <OutputFormat>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</OutputFormat>
      <Location>hdfs://hadoop102:8020/user/hive/warehouse/score</Location>
    </table>
    <table id="302" parent="3" name="stu">
      <Properties>bucketing_version
2
transient_lastDdlTime
1587719764</Properties>
      <RowFormatSerde>org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</RowFormatSerde>
      <InputFormat>org.apache.hadoop.mapred.TextInputFormat</InputFormat>
      <OutputFormat>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</OutputFormat>
      <Location>hdfs://hadoop102:8020/user/hive/warehouse/stu</Location>
    </table>
    <table id="303" parent="3" name="stu1">
      <Properties>bucketing_version
2
transient_lastDdlTime
1587904179</Properties>
      <RowFormatSerde>org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</RowFormatSerde>
      <SerdeProperties>field.delim
\t
serialization.format
\t</SerdeProperties>
      <InputFormat>org.apache.hadoop.mapred.TextInputFormat</InputFormat>
      <OutputFormat>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</OutputFormat>
      <Location>hdfs://hadoop102:8020/user/hive/warehouse/stu1</Location>
    </table>
    <table id="304" parent="3" name="stu3">
      <Properties>transient_lastDdlTime
1587904720</Properties>
      <RowFormatSerde>org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</RowFormatSerde>
      <InputFormat>org.apache.hadoop.mapred.TextInputFormat</InputFormat>
      <OutputFormat>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</OutputFormat>
      <Location>hdfs://hadoop102:8020/user/hive/warehouse/stu3</Location>
    </table>
    <table id="305" parent="3" name="stu4">
      <Properties>transient_lastDdlTime
1587904626</Properties>
      <RowFormatSerde>org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</RowFormatSerde>
      <SerdeProperties>field.delim
\t
serialization.format
\t</SerdeProperties>
      <InputFormat>org.apache.hadoop.mapred.TextInputFormat</InputFormat>
      <OutputFormat>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</OutputFormat>
      <Location>hdfs://hadoop102:8020/user/hive/warehouse/stu4</Location>
    </table>
    <table id="306" parent="3" name="stu5">
      <Properties>bucketing_version
2
transient_lastDdlTime
1587904807</Properties>
      <RowFormatSerde>org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</RowFormatSerde>
      <SerdeProperties>field.delim
\t
serialization.format
\t</SerdeProperties>
      <InputFormat>org.apache.hadoop.mapred.TextInputFormat</InputFormat>
      <OutputFormat>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</OutputFormat>
      <Location>hdfs://hadoop102:8020/user/hive/warehouse/mydb.db/stu3</Location>
    </table>
    <table id="307" parent="3" name="stu6">
      <Properties>bucketing_version
2
transient_lastDdlTime
1587904956</Properties>
      <RowFormatSerde>org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</RowFormatSerde>
      <SerdeProperties>field.delim
\t
serialization.format
\t</SerdeProperties>
      <InputFormat>org.apache.hadoop.mapred.TextInputFormat</InputFormat>
      <OutputFormat>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</OutputFormat>
      <Location>hdfs://hadoop102:8020/user/hive/warehouse/stu3</Location>
    </table>
    <table id="308" parent="3" name="stu7">
      <Properties>bucketing_version
2
transient_lastDdlTime
1587905592</Properties>
      <RowFormatSerde>org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</RowFormatSerde>
      <SerdeProperties>field.delim
\t
serialization.format
\t</SerdeProperties>
      <InputFormat>org.apache.hadoop.mapred.TextInputFormat</InputFormat>
      <OutputFormat>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</OutputFormat>
      <Location>hdfs://hadoop102:8020/user/hive/warehouse/mydb.db/stu4</Location>
    </table>
    <table id="309" parent="3" name="stu_buck">
      <Properties>bucketing_version
2
transient_lastDdlTime
1587968733</Properties>
      <BucketsNum>3</BucketsNum>
      <RowFormatSerde>org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</RowFormatSerde>
      <SerdeProperties>field.delim
\t
serialization.format
\t</SerdeProperties>
      <InputFormat>org.apache.hadoop.mapred.TextInputFormat</InputFormat>
      <OutputFormat>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</OutputFormat>
      <Location>hdfs://hadoop102:8020/user/hive/warehouse/stu_buck</Location>
    </table>
    <table id="310" parent="3" name="stu_buck2">
      <Properties>bucketing_version
2
transient_lastDdlTime
1587986541</Properties>
      <BucketsNum>4</BucketsNum>
      <RowFormatSerde>org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</RowFormatSerde>
      <SerdeProperties>field.delim
\t
serialization.format
\t</SerdeProperties>
      <InputFormat>org.apache.hadoop.mapred.TextInputFormat</InputFormat>
      <OutputFormat>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</OutputFormat>
      <Location>hdfs://hadoop102:8020/user/hive/warehouse/stu_buck2</Location>
    </table>
    <table id="311" parent="3" name="stu_dp">
      <Properties>bucketing_version
2
transient_lastDdlTime
1587985266</Properties>
      <RowFormatSerde>org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</RowFormatSerde>
      <SerdeProperties>field.delim
\t
serialization.format
\t</SerdeProperties>
      <InputFormat>org.apache.hadoop.mapred.TextInputFormat</InputFormat>
      <OutputFormat>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</OutputFormat>
      <Location>hdfs://hadoop102:8020/user/hive/warehouse/stu_dp</Location>
    </table>
    <table id="312" parent="3" name="stu_pa">
      <Properties>bucketing_version
2
transient_lastDdlTime
1591881003</Properties>
      <RowFormatSerde>org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</RowFormatSerde>
      <SerdeProperties>field.delim
\t
serialization.format
\t</SerdeProperties>
      <InputFormat>org.apache.hadoop.mapred.TextInputFormat</InputFormat>
      <OutputFormat>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</OutputFormat>
      <Location>hdfs://hadoop102:8020/user/hive/warehouse/stu_pa</Location>
    </table>
    <table id="313" parent="3" name="stu_pt">
      <Properties>bucketing_version
2
transient_lastDdlTime
1587985656</Properties>
      <RowFormatSerde>org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</RowFormatSerde>
      <SerdeProperties>field.delim
\t
serialization.format
\t</SerdeProperties>
      <InputFormat>org.apache.hadoop.mapred.TextInputFormat</InputFormat>
      <OutputFormat>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</OutputFormat>
      <Location>hdfs://hadoop102:8020/user/hive/warehouse/stu_pt</Location>
    </table>
    <table id="314" parent="3" name="student">
      <Properties>bucketing_version
2
transient_lastDdlTime
1588309639</Properties>
      <RowFormatSerde>org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</RowFormatSerde>
      <SerdeProperties>field.delim
\t
serialization.format
\t</SerdeProperties>
      <InputFormat>org.apache.hadoop.mapred.TextInputFormat</InputFormat>
      <OutputFormat>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</OutputFormat>
      <Location>hdfs://hadoop102:8020/user/hive/warehouse/student</Location>
    </table>
    <table id="315" parent="3" name="student_external">
      <Properties>transient_lastDdlTime
1587903250</Properties>
      <RowFormatSerde>org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</RowFormatSerde>
      <SerdeProperties>field.delim
\t
serialization.format
\t</SerdeProperties>
      <InputFormat>org.apache.hadoop.mapred.TextInputFormat</InputFormat>
      <OutputFormat>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</OutputFormat>
      <Location>hdfs://hadoop102:8020/user/hive/warehouse/student_external</Location>
    </table>
    <table id="316" parent="3" name="student_ma_ex">
      <Properties>EXTERNAL
FALSE
bucketing_version
2
last_modified_by
atguigu
last_modified_time
1587903475
transient_lastDdlTime
1587903475</Properties>
      <RowFormatSerde>org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</RowFormatSerde>
      <SerdeProperties>field.delim
\t
serialization.format
\t</SerdeProperties>
      <InputFormat>org.apache.hadoop.mapred.TextInputFormat</InputFormat>
      <OutputFormat>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</OutputFormat>
      <Location>hdfs://hadoop102:8020/user/hive/warehouse/student_ma_ex</Location>
    </table>
    <table id="317" parent="3" name="student_manage">
      <Properties>transient_lastDdlTime
1587903171</Properties>
      <RowFormatSerde>org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</RowFormatSerde>
      <SerdeProperties>field.delim
\t
serialization.format
\t</SerdeProperties>
      <InputFormat>org.apache.hadoop.mapred.TextInputFormat</InputFormat>
      <OutputFormat>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</OutputFormat>
      <Location>hdfs://hadoop102:8020/user/hive/warehouse/student_manage</Location>
    </table>
    <table id="318" parent="3" name="tes">
      <Properties>bucketing_version
2
transient_lastDdlTime
1587984056</Properties>
      <RowFormatSerde>org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</RowFormatSerde>
      <SerdeProperties>field.delim
\t
serialization.format
\t</SerdeProperties>
      <InputFormat>org.apache.hadoop.mapred.TextInputFormat</InputFormat>
      <OutputFormat>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</OutputFormat>
      <Location>hdfs://hadoop102:8020/user/hive/warehouse/tes</Location>
    </table>
    <table id="319" parent="3" name="tes1">
      <Properties>bucketing_version
2
transient_lastDdlTime
1587984266</Properties>
      <RowFormatSerde>org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</RowFormatSerde>
      <SerdeProperties>field.delim
\t
serialization.format
\t</SerdeProperties>
      <InputFormat>org.apache.hadoop.mapred.TextInputFormat</InputFormat>
      <OutputFormat>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</OutputFormat>
      <Location>hdfs://hadoop102:8020/user/hive/warehouse/tes1</Location>
    </table>
    <table id="320" parent="3" name="user_info">
      <Properties>bucketing_version
2
transient_lastDdlTime
1588938198</Properties>
      <RowFormatSerde>org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</RowFormatSerde>
      <SerdeProperties>field.delim
\t
serialization.format
\t</SerdeProperties>
      <InputFormat>org.apache.hadoop.mapred.TextInputFormat</InputFormat>
      <OutputFormat>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</OutputFormat>
      <Location>hdfs://hadoop102:8020/user/hive/warehouse/user_info</Location>
    </table>
    <table id="321" parent="3" name="visit">
      <Properties>bucketing_version
2
transient_lastDdlTime
1588081684</Properties>
      <RowFormatSerde>org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</RowFormatSerde>
      <SerdeProperties>field.delim
\t
serialization.format
\t</SerdeProperties>
      <InputFormat>org.apache.hadoop.mapred.TextInputFormat</InputFormat>
      <OutputFormat>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</OutputFormat>
      <Location>hdfs://hadoop102:8020/user/hive/warehouse/visit</Location>
    </table>
    <view id="322" parent="3" name="user_info_view">
      <Properties>bucketing_version
2
transient_lastDdlTime
1588942411</Properties>
      <SourceTextLength>197</SourceTextLength>
    </view>
    <table id="323" parent="4" name="external_stu"/>
    <table id="324" parent="4" name="stu">
      <Properties>bucketing_version
2
transient_lastDdlTime
1587719764</Properties>
      <RowFormatSerde>org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</RowFormatSerde>
      <InputFormat>org.apache.hadoop.mapred.TextInputFormat</InputFormat>
      <OutputFormat>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</OutputFormat>
      <Location>hdfs://hadoop102:8020/user/hive/warehouse/stu</Location>
    </table>
    <table id="325" parent="4" name="stu1">
      <Properties>bucketing_version
2
transient_lastDdlTime
1587904179</Properties>
      <RowFormatSerde>org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</RowFormatSerde>
      <SerdeProperties>field.delim
\t
serialization.format
\t</SerdeProperties>
      <InputFormat>org.apache.hadoop.mapred.TextInputFormat</InputFormat>
      <OutputFormat>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</OutputFormat>
      <Location>hdfs://hadoop102:8020/user/hive/warehouse/stu1</Location>
    </table>
    <table id="326" parent="4" name="stu2"/>
    <table id="327" parent="4" name="stu33"/>
    <table id="328" parent="4" name="stu4">
      <Properties>transient_lastDdlTime
1587904626</Properties>
      <RowFormatSerde>org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</RowFormatSerde>
      <SerdeProperties>field.delim
\t
serialization.format
\t</SerdeProperties>
      <InputFormat>org.apache.hadoop.mapred.TextInputFormat</InputFormat>
      <OutputFormat>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</OutputFormat>
      <Location>hdfs://hadoop102:8020/user/hive/warehouse/stu4</Location>
    </table>
    <table id="329" parent="4" name="stu5">
      <Properties>bucketing_version
2
transient_lastDdlTime
1587904807</Properties>
      <RowFormatSerde>org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</RowFormatSerde>
      <SerdeProperties>field.delim
\t
serialization.format
\t</SerdeProperties>
      <InputFormat>org.apache.hadoop.mapred.TextInputFormat</InputFormat>
      <OutputFormat>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</OutputFormat>
      <Location>hdfs://hadoop102:8020/user/hive/warehouse/mydb.db/stu3</Location>
    </table>
    <table id="330" parent="5" name="stu">
      <Properties>bucketing_version
2
transient_lastDdlTime
1587719764</Properties>
      <RowFormatSerde>org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</RowFormatSerde>
      <InputFormat>org.apache.hadoop.mapred.TextInputFormat</InputFormat>
      <OutputFormat>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</OutputFormat>
      <Location>hdfs://hadoop102:8020/user/hive/warehouse/stu</Location>
    </table>
    <table id="331" parent="5" name="stu2"/>
    <table id="332" parent="5" name="student">
      <Properties>bucketing_version
2
transient_lastDdlTime
1588309639</Properties>
      <RowFormatSerde>org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</RowFormatSerde>
      <SerdeProperties>field.delim
\t
serialization.format
\t</SerdeProperties>
      <InputFormat>org.apache.hadoop.mapred.TextInputFormat</InputFormat>
      <OutputFormat>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</OutputFormat>
      <Location>hdfs://hadoop102:8020/user/hive/warehouse/student</Location>
    </table>
    <table id="333" parent="5" name="student1"/>
    <table id="334" parent="5" name="student2"/>
    <table id="335" parent="5" name="student3"/>
    <column id="336" parent="265" name="city_id">
      <Position>1</Position>
      <DataType>bigint|-5s</DataType>
    </column>
    <column id="337" parent="265" name="city_name">
      <Position>2</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="338" parent="265" name="area">
      <Position>3</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="339" parent="266" name="product_id">
      <Position>1</Position>
      <DataType>bigint|-5s</DataType>
    </column>
    <column id="340" parent="266" name="product_name">
      <Position>2</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="341" parent="266" name="extend_info">
      <Position>3</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="342" parent="267" name="date">
      <Position>1</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="343" parent="267" name="user_id">
      <Position>2</Position>
      <DataType>bigint|-5s</DataType>
    </column>
    <column id="344" parent="267" name="session_id">
      <Position>3</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="345" parent="267" name="page_id">
      <Position>4</Position>
      <DataType>bigint|-5s</DataType>
    </column>
    <column id="346" parent="267" name="action_time">
      <Position>5</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="347" parent="267" name="search_keyword">
      <Position>6</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="348" parent="267" name="click_category_id">
      <Position>7</Position>
      <DataType>bigint|-5s</DataType>
    </column>
    <column id="349" parent="267" name="click_product_id">
      <Position>8</Position>
      <DataType>bigint|-5s</DataType>
    </column>
    <column id="350" parent="267" name="order_category_ids">
      <Position>9</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="351" parent="267" name="order_product_ids">
      <Position>10</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="352" parent="267" name="pay_category_ids">
      <Position>11</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="353" parent="267" name="pay_product_ids">
      <Position>12</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="354" parent="267" name="city_id">
      <Position>13</Position>
      <DataType>bigint|-5s</DataType>
    </column>
    <column id="355" parent="268" name="id">
      <Position>1</Position>
      <DataType>int|4s</DataType>
    </column>
    <column id="356" parent="269" name="userid">
      <Position>1</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="357" parent="269" name="visitdate">
      <Position>2</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="358" parent="269" name="visitcount">
      <Position>3</Position>
      <DataType>int|4s</DataType>
    </column>
    <column id="359" parent="270" name="name">
      <Position>1</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="360" parent="270" name="orderdate">
      <Position>2</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="361" parent="270" name="cost">
      <Position>3</Position>
      <DataType>int|4s</DataType>
    </column>
    <column id="362" parent="271" name="deptno">
      <Position>1</Position>
      <DataType>int|4s</DataType>
    </column>
    <column id="363" parent="271" name="dname">
      <Position>2</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="364" parent="271" name="loc">
      <Position>3</Position>
      <DataType>int|4s</DataType>
    </column>
    <column id="365" parent="272" name="id">
      <Position>1</Position>
      <DataType>int|4s</DataType>
    </column>
    <column id="366" parent="272" name="name">
      <Position>2</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="367" parent="272" name="month">
      <Position>3</Position>
      <DataType>string|12s</DataType>
      <Type>partitioning</Type>
    </column>
    <column id="368" parent="273" name="empno">
      <Position>1</Position>
      <DataType>int|4s</DataType>
    </column>
    <column id="369" parent="273" name="ename">
      <Position>2</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="370" parent="273" name="job">
      <Position>3</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="371" parent="273" name="mgr">
      <Position>4</Position>
      <DataType>int|4s</DataType>
    </column>
    <column id="372" parent="273" name="hiredate">
      <Position>5</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="373" parent="273" name="sal">
      <Position>6</Position>
      <DataType>double|8s</DataType>
    </column>
    <column id="374" parent="273" name="comm">
      <Position>7</Position>
      <DataType>double|8s</DataType>
    </column>
    <column id="375" parent="273" name="deptno">
      <Position>8</Position>
      <DataType>int|4s</DataType>
    </column>
    <column id="376" parent="274" name="name">
      <Position>1</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="377" parent="274" name="dept_id">
      <Position>2</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="378" parent="274" name="sex">
      <Position>3</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="379" parent="275" name="videoid">
      <Position>1</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="380" parent="275" name="uploader">
      <Position>2</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="381" parent="275" name="age">
      <Position>3</Position>
      <DataType>int|4s</DataType>
    </column>
    <column id="382" parent="275" name="category">
      <Position>4</Position>
      <DataType>array&lt;string&gt;|2003s</DataType>
    </column>
    <column id="383" parent="275" name="length">
      <Position>5</Position>
      <DataType>int|4s</DataType>
    </column>
    <column id="384" parent="275" name="views">
      <Position>6</Position>
      <DataType>int|4s</DataType>
    </column>
    <column id="385" parent="275" name="rate">
      <Position>7</Position>
      <DataType>float|6s</DataType>
    </column>
    <column id="386" parent="275" name="ratings">
      <Position>8</Position>
      <DataType>int|4s</DataType>
    </column>
    <column id="387" parent="275" name="comments">
      <Position>9</Position>
      <DataType>int|4s</DataType>
    </column>
    <column id="388" parent="275" name="relatedid">
      <Position>10</Position>
      <DataType>array&lt;string&gt;|2003s</DataType>
    </column>
    <column id="389" parent="276" name="videoid">
      <Position>1</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="390" parent="276" name="uploader">
      <Position>2</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="391" parent="276" name="age">
      <Position>3</Position>
      <DataType>int|4s</DataType>
    </column>
    <column id="392" parent="276" name="category">
      <Position>4</Position>
      <DataType>array&lt;string&gt;|2003s</DataType>
    </column>
    <column id="393" parent="276" name="length">
      <Position>5</Position>
      <DataType>int|4s</DataType>
    </column>
    <column id="394" parent="276" name="views">
      <Position>6</Position>
      <DataType>int|4s</DataType>
    </column>
    <column id="395" parent="276" name="rate">
      <Position>7</Position>
      <DataType>float|6s</DataType>
    </column>
    <column id="396" parent="276" name="ratings">
      <Position>8</Position>
      <DataType>int|4s</DataType>
    </column>
    <column id="397" parent="276" name="comments">
      <Position>9</Position>
      <DataType>int|4s</DataType>
    </column>
    <column id="398" parent="276" name="relatedid">
      <Position>10</Position>
      <DataType>array&lt;string&gt;|2003s</DataType>
    </column>
    <column id="399" parent="277" name="uploader">
      <Position>1</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="400" parent="277" name="videos">
      <Position>2</Position>
      <DataType>int|4s</DataType>
    </column>
    <column id="401" parent="277" name="friends">
      <Position>3</Position>
      <DataType>int|4s</DataType>
    </column>
    <column id="402" parent="278" name="uploader">
      <Position>1</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="403" parent="278" name="videos">
      <Position>2</Position>
      <DataType>int|4s</DataType>
    </column>
    <column id="404" parent="278" name="friends">
      <Position>3</Position>
      <DataType>int|4s</DataType>
    </column>
    <column id="405" parent="279" name="payment_info_payment_way">
      <Position>1</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="406" parent="279" name="payment_info_user_id">
      <Position>2</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="407" parent="279" name="payment_info_payment_amount">
      <Position>3</Position>
      <DataType>double|8s</DataType>
    </column>
    <column id="408" parent="280" name="payment_info_payment_way">
      <Position>1</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="409" parent="280" name="payment_info_user_id">
      <Position>2</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="410" parent="280" name="payment_info_payment_amount">
      <Position>3</Position>
      <DataType>double|8s</DataType>
    </column>
    <column id="411" parent="281" name="id">
      <Position>1</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="412" parent="281" name="user_name">
      <Position>2</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="413" parent="281" name="gender">
      <Position>3</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="414" parent="281" name="user_level">
      <Position>4</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="415" parent="281" name="area">
      <Position>5</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="416" parent="281" name="dt">
      <Position>6</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="417" parent="282" name="id">
      <Position>1</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="418" parent="282" name="user_name">
      <Position>2</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="419" parent="282" name="gender">
      <Position>3</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="420" parent="282" name="user_level">
      <Position>4</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="421" parent="282" name="area">
      <Position>5</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="422" parent="282" name="dt">
      <Position>6</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="423" parent="283" name="id">
      <Position>1</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="424" parent="283" name="user_name">
      <Position>2</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="425" parent="283" name="gender">
      <Position>3</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="426" parent="283" name="user_level">
      <Position>4</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="427" parent="283" name="area">
      <Position>5</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="428" parent="283" name="dt">
      <Position>6</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="429" parent="284" name="id">
      <Position>1</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="430" parent="284" name="user_name">
      <Position>2</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="431" parent="284" name="gender">
      <Position>3</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="432" parent="284" name="user_level">
      <Position>4</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="433" parent="284" name="area">
      <Position>5</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="434" parent="284" name="dt">
      <Position>6</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="435" parent="285" name="id">
      <Position>1</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="436" parent="285" name="user_name">
      <Position>2</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="437" parent="285" name="gender">
      <Position>3</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="438" parent="285" name="user_level">
      <Position>4</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="439" parent="285" name="area">
      <Position>5</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="440" parent="285" name="dt">
      <Position>6</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="441" parent="286" name="id">
      <Position>1</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="442" parent="286" name="user_name">
      <Position>2</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="443" parent="286" name="gender">
      <Position>3</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="444" parent="286" name="user_level">
      <Position>4</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="445" parent="286" name="area">
      <Position>5</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="446" parent="286" name="dt">
      <Position>6</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="447" parent="287" name="payment_info_payment_way">
      <Position>1</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="448" parent="287" name="user_info_gender">
      <Position>2</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="449" parent="287" name="user_info_user_level">
      <Position>3</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="450" parent="287" name="user_info_area">
      <Position>4</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="451" parent="287" name="payment_info_payment_amount">
      <Position>5</Position>
      <DataType>double|8s</DataType>
    </column>
    <column id="452" parent="288" name="payment_info_payment_way">
      <Position>1</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="453" parent="288" name="user_info_view_gender">
      <Position>2</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="454" parent="288" name="user_info_view_user_level">
      <Position>3</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="455" parent="288" name="user_info_view_area">
      <Position>4</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="456" parent="288" name="payment_info_payment_amount">
      <Position>5</Position>
      <DataType>double|8s</DataType>
    </column>
    <column id="457" parent="289" name="payment_info_payment_way">
      <Position>1</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="458" parent="289" name="user_info_view_gender">
      <Position>2</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="459" parent="289" name="user_info_view_user_level">
      <Position>3</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="460" parent="289" name="user_info_view_area">
      <Position>4</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="461" parent="289" name="payment_info_payment_amount">
      <Position>5</Position>
      <DataType>double|8s</DataType>
    </column>
    <column id="462" parent="290" name="payment_info_payment_way">
      <Position>1</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="463" parent="290" name="user_info_view_gender">
      <Position>2</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="464" parent="290" name="user_info_view_user_level">
      <Position>3</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="465" parent="290" name="user_info_view_area">
      <Position>4</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="466" parent="290" name="payment_info_payment_amount">
      <Position>5</Position>
      <DataType>double|8s</DataType>
    </column>
    <column id="467" parent="291" name="payment_info_payment_way">
      <Position>1</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="468" parent="291" name="user_info_view_gender">
      <Position>2</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="469" parent="291" name="user_info_view_user_level">
      <Position>3</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="470" parent="291" name="user_info_view_area">
      <Position>4</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="471" parent="291" name="payment_info_payment_amount">
      <Position>5</Position>
      <DataType>double|8s</DataType>
    </column>
    <column id="472" parent="292" name="track_time">
      <Position>1</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="473" parent="292" name="url">
      <Position>2</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="474" parent="292" name="session_id">
      <Position>3</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="475" parent="292" name="referer">
      <Position>4</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="476" parent="292" name="ip">
      <Position>5</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="477" parent="292" name="end_user_id">
      <Position>6</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="478" parent="292" name="city_id">
      <Position>7</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="479" parent="293" name="track_time">
      <Position>1</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="480" parent="293" name="url">
      <Position>2</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="481" parent="293" name="session_id">
      <Position>3</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="482" parent="293" name="referer">
      <Position>4</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="483" parent="293" name="ip">
      <Position>5</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="484" parent="293" name="end_user_id">
      <Position>6</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="485" parent="293" name="city_id">
      <Position>7</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="486" parent="294" name="track_time">
      <Position>1</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="487" parent="294" name="url">
      <Position>2</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="488" parent="294" name="session_id">
      <Position>3</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="489" parent="294" name="referer">
      <Position>4</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="490" parent="294" name="ip">
      <Position>5</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="491" parent="294" name="end_user_id">
      <Position>6</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="492" parent="294" name="city_id">
      <Position>7</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="493" parent="295" name="track_time">
      <Position>1</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="494" parent="295" name="url">
      <Position>2</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="495" parent="295" name="session_id">
      <Position>3</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="496" parent="295" name="referer">
      <Position>4</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="497" parent="295" name="ip">
      <Position>5</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="498" parent="295" name="end_user_id">
      <Position>6</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="499" parent="295" name="city_id">
      <Position>7</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="500" parent="296" name="track_time">
      <Position>1</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="501" parent="296" name="url">
      <Position>2</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="502" parent="296" name="session_id">
      <Position>3</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="503" parent="296" name="referer">
      <Position>4</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="504" parent="296" name="ip">
      <Position>5</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="505" parent="296" name="end_user_id">
      <Position>6</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="506" parent="296" name="city_id">
      <Position>7</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="507" parent="297" name="track_time">
      <Position>1</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="508" parent="297" name="url">
      <Position>2</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="509" parent="297" name="session_id">
      <Position>3</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="510" parent="297" name="referer">
      <Position>4</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="511" parent="297" name="ip">
      <Position>5</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="512" parent="297" name="end_user_id">
      <Position>6</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="513" parent="297" name="city_id">
      <Position>7</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="514" parent="298" name="movie">
      <Position>1</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="515" parent="298" name="category">
      <Position>2</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="516" parent="299" name="id">
      <Position>1</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="517" parent="299" name="user_id">
      <Position>2</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="518" parent="299" name="payment_way">
      <Position>3</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="519" parent="299" name="payment_amount">
      <Position>4</Position>
      <DataType>double|8s</DataType>
    </column>
    <column id="520" parent="299" name="dt">
      <Position>5</Position>
      <DataType>string|12s</DataType>
      <Type>partitioning</Type>
    </column>
    <column id="521" parent="300" name="name">
      <Position>1</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="522" parent="300" name="constellation">
      <Position>2</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="523" parent="300" name="blood_type">
      <Position>3</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="524" parent="301" name="name">
      <Position>1</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="525" parent="301" name="subject">
      <Position>2</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="526" parent="301" name="score">
      <Position>3</Position>
      <DataType>int|4s</DataType>
    </column>
    <column id="527" parent="302" name="id">
      <Position>1</Position>
      <DataType>int|4s</DataType>
    </column>
    <column id="528" parent="302" name="name">
      <Position>2</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="529" parent="303" name="id">
      <Position>1</Position>
      <DataType>int|4s</DataType>
    </column>
    <column id="530" parent="303" name="name">
      <Position>2</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="531" parent="304" name="id">
      <Position>1</Position>
      <DataType>int|4s</DataType>
    </column>
    <column id="532" parent="304" name="name">
      <Position>2</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="533" parent="305" name="id">
      <Position>1</Position>
      <DataType>int|4s</DataType>
    </column>
    <column id="534" parent="305" name="name">
      <Position>2</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="535" parent="306" name="id">
      <Position>1</Position>
      <DataType>int|4s</DataType>
    </column>
    <column id="536" parent="306" name="name">
      <Position>2</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="537" parent="307" name="id">
      <Position>1</Position>
      <DataType>int|4s</DataType>
    </column>
    <column id="538" parent="307" name="name">
      <Position>2</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="539" parent="308" name="id">
      <Position>1</Position>
      <DataType>int|4s</DataType>
    </column>
    <column id="540" parent="308" name="name">
      <Position>2</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="541" parent="309" name="id">
      <Position>1</Position>
      <DataType>int|4s</DataType>
      <Type>clustering</Type>
    </column>
    <column id="542" parent="309" name="name">
      <Position>2</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="543" parent="310" name="id">
      <Position>1</Position>
      <DataType>int|4s</DataType>
      <Type>clustering</Type>
    </column>
    <column id="544" parent="310" name="name">
      <Position>2</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="545" parent="311" name="id">
      <Position>1</Position>
      <DataType>int|4s</DataType>
    </column>
    <column id="546" parent="311" name="name">
      <Position>2</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="547" parent="311" name="sex">
      <Position>3</Position>
      <DataType>string|12s</DataType>
      <Type>partitioning</Type>
    </column>
    <column id="548" parent="312" name="id">
      <Position>1</Position>
      <DataType>int|4s</DataType>
    </column>
    <column id="549" parent="312" name="name">
      <Position>2</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="550" parent="312" name="month">
      <Position>3</Position>
      <DataType>string|12s</DataType>
      <Type>partitioning</Type>
    </column>
    <column id="551" parent="313" name="id">
      <Position>1</Position>
      <DataType>int|4s</DataType>
    </column>
    <column id="552" parent="313" name="name">
      <Position>2</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="553" parent="313" name="sex">
      <Position>3</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="554" parent="314" name="id">
      <Position>1</Position>
      <DataType>int|4s</DataType>
    </column>
    <column id="555" parent="314" name="name">
      <Position>2</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="556" parent="315" name="id">
      <Position>1</Position>
      <DataType>int|4s</DataType>
    </column>
    <column id="557" parent="315" name="name">
      <Position>2</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="558" parent="316" name="id">
      <Position>1</Position>
      <Comment>Student&apos;s Id</Comment>
      <DataType>int|4s</DataType>
    </column>
    <column id="559" parent="316" name="name">
      <Position>2</Position>
      <Comment>Student&apos;s Name</Comment>
      <DataType>string|12s</DataType>
    </column>
    <column id="560" parent="317" name="id">
      <Position>1</Position>
      <DataType>int|4s</DataType>
    </column>
    <column id="561" parent="317" name="name">
      <Position>2</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="562" parent="318" name="id">
      <Position>1</Position>
      <DataType>int|4s</DataType>
    </column>
    <column id="563" parent="318" name="name">
      <Position>2</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="564" parent="318" name="data">
      <Position>3</Position>
      <DataType>string|12s</DataType>
      <Type>partitioning</Type>
    </column>
    <column id="565" parent="319" name="id">
      <Position>1</Position>
      <DataType>int|4s</DataType>
    </column>
    <column id="566" parent="319" name="name">
      <Position>2</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="567" parent="319" name="data">
      <Position>3</Position>
      <DataType>string|12s</DataType>
      <Type>partitioning</Type>
    </column>
    <column id="568" parent="319" name="hour">
      <Position>4</Position>
      <DataType>string|12s</DataType>
      <Type>partitioning</Type>
    </column>
    <column id="569" parent="320" name="id">
      <Position>1</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="570" parent="320" name="user_name">
      <Position>2</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="571" parent="320" name="gender">
      <Position>3</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="572" parent="320" name="user_level">
      <Position>4</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="573" parent="320" name="area">
      <Position>5</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="574" parent="320" name="dt">
      <Position>6</Position>
      <DataType>string|12s</DataType>
      <Type>partitioning</Type>
    </column>
    <column id="575" parent="321" name="user_id">
      <Position>1</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="576" parent="321" name="shop">
      <Position>2</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="577" parent="322" name="id">
      <Position>1</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="578" parent="322" name="user_name">
      <Position>2</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="579" parent="322" name="gender">
      <Position>3</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="580" parent="322" name="user_level">
      <Position>4</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="581" parent="322" name="area">
      <Position>5</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="582" parent="322" name="dt">
      <Position>6</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="583" parent="323" name="id">
      <Position>1</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="584" parent="323" name="name">
      <Position>2</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="585" parent="324" name="id">
      <Position>1</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="586" parent="324" name="name">
      <Position>2</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="587" parent="325" name="id">
      <Position>1</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="588" parent="325" name="name">
      <Position>2</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="589" parent="326" name="id">
      <Position>1</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="590" parent="326" name="name">
      <Position>2</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="591" parent="327" name="ids">
      <Position>1</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="592" parent="327" name="name">
      <Position>2</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="593" parent="327" name="age">
      <Position>3</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="594" parent="328" name="id">
      <Position>1</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="595" parent="328" name="name">
      <Position>2</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="596" parent="329" name="id">
      <Position>1</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="597" parent="329" name="name">
      <Position>2</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="598" parent="330" name="id">
      <Position>1</Position>
      <DataType>int|4s</DataType>
    </column>
    <column id="599" parent="330" name="name">
      <Position>2</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="600" parent="331" name="id">
      <Position>1</Position>
      <DataType>int|4s</DataType>
    </column>
    <column id="601" parent="331" name="name">
      <Position>2</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="602" parent="332" name="id">
      <Position>1</Position>
      <DataType>int|4s</DataType>
    </column>
    <column id="603" parent="332" name="name">
      <Position>2</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="604" parent="333" name="id">
      <Position>1</Position>
      <DataType>int|4s</DataType>
    </column>
    <column id="605" parent="333" name="name">
      <Position>2</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="606" parent="334" name="id">
      <Position>1</Position>
      <DataType>int|4s</DataType>
    </column>
    <column id="607" parent="334" name="name">
      <Position>2</Position>
      <DataType>string|12s</DataType>
    </column>
    <column id="608" parent="335" name="id">
      <Position>1</Position>
      <Comment>Student&apos;s Id</Comment>
      <DataType>int|4s</DataType>
    </column>
    <column id="609" parent="335" name="name">
      <Position>2</Position>
      <Comment>Student&apos;s Name</Comment>
      <DataType>string|12s</DataType>
    </column>
  </database-model>
</dataSource>